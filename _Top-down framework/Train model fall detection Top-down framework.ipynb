{"cells":[{"cell_type":"markdown","metadata":{"id":"QWtzUpwreQp3"},"source":["# **Di chuyển đến thư mục làm việc**"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23147,"status":"ok","timestamp":1686212277491,"user":{"displayName":"nguyen toan","userId":"14848113097500887617"},"user_tz":-420},"id":"oDkno5Si5u8b","outputId":"d248dd38-1e3a-4e3a-c8f5-9c2ed37b4870"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive/\", force_remount=True)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1686212277491,"user":{"displayName":"nguyen toan","userId":"14848113097500887617"},"user_tz":-420},"id":"24bWpd5ZXeD1","outputId":"037618b4-081f-4169-96ef-d4475f90eca9"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1-VazRbs1t_EDwA_O5hAtA7-GV8f_IHJE/PBL5\n"]}],"source":["cd /content/drive/MyDrive/PBL5"]},{"cell_type":"markdown","metadata":{"id":"bWmf_xDmeW0H"},"source":["# **Cài và khai báo thư viện**"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"YHfzsVtY527B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686212288907,"user_tz":-420,"elapsed":11418,"user":{"displayName":"nguyen toan","userId":"14848113097500887617"}},"outputId":"598bdd1d-355b-45d6-e8fd-271b840d747a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ultralytics\n","  Downloading ultralytics-8.0.114-py3-none-any.whl (595 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m595.4/595.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.7.0.72)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (8.4.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.27.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.10.1)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.1+cu118)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.15.2+cu118)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.65.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (16.0.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n","Installing collected packages: ultralytics\n","Successfully installed ultralytics-8.0.114\n"]}],"source":["!pip install --upgrade scikit-learn\n","!pip install --upgrade ultralytics"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"GjOFksbd541K","executionInfo":{"status":"ok","timestamp":1686212314562,"user_tz":-420,"elapsed":25659,"user":{"displayName":"nguyen toan","userId":"14848113097500887617"}}},"outputs":[],"source":["import os\n","import cv2\n","import math\n","import time\n","import datetime\n","import numpy as np\n","import pandas as pd\n","import random\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.utils import to_categorical, plot_model\n","from google.colab.patches import cv2_imshow\n","\n","from sklearn.utils import class_weight\n","from keras import backend as K\n","from sklearn.metrics import f1_score, precision_recall_fscore_support, confusion_matrix\n","from ultralytics import YOLO\n","from keras.layers import Dense, LSTM, Dropout\n","from keras.models import Sequential\n","import seaborn as sns\n","from keras.callbacks import CSVLogger"]},{"cell_type":"markdown","metadata":{"id":"hFc-J29Ieabf"},"source":["# **Các hàm xử lý**"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"wNpJmVQ87bUy","executionInfo":{"status":"ok","timestamp":1686212314562,"user_tz":-420,"elapsed":4,"user":{"displayName":"nguyen toan","userId":"14848113097500887617"}}},"outputs":[],"source":["# lưu file npy (features của dataset)\n","def save_to_npy(label, features):\n","    with open(label, \"wb\") as f:\n","        np.save(f, features)\n","        f.close()\n","\n","\n","# Lấy tất cả đường dẫn của tập dataset\n","def get_list_video():\n","    videos = []\n","    folder_path = 'Dataset'\n","    for sub_folder in os.listdir(folder_path):\n","        # Duyệt qua tất cả các file video\n","        for filename in os.listdir(os.path.join(folder_path, sub_folder)):\n","            video_path = os.path.join(folder_path, sub_folder)\n","            video_path = os.path.join(video_path, filename)\n","            videos.append(video_path)\n","    return videos\n","\n","\n","# lấy đặc trưng của 1 frame\n","def get_feature(mask, s):\n","    h, w = mask.shape\n","\n","    # Tính ROI (Region Of Interest: vùng quan tâm) các vùng A1, A2, A3, A4, A5\n","    roi = [0, 0, 0, 0, 0]\n","\n","    coor = (w // 2, h // 2)\n","    tan55 = 1.428  # tan(55)\n","\n","    for i in range(h):\n","        i = i - coor[1]\n","        for j in range(w):\n","            j = j - coor[0]\n","            if (j <= 0) and (j - i > 0):\n","                roi[0] += mask[i, j]\n","            elif (j > 0) and (j + i <= 0):\n","                roi[1] += mask[i + coor[1], j + coor[0]]\n","            elif (j - i <= 0) and (i + tan55 * j <= 0):\n","                roi[2] += mask[i + coor[1], j + coor[0]]\n","            elif (j + i > 0) and (i - tan55 * j > 0):\n","                roi[3] += mask[i + coor[1], j + coor[0]]\n","            else:\n","                roi[4] += mask[i + coor[1], j + coor[0]]\n","    \n","    return [r / sum(roi) for r in roi]"]},{"cell_type":"markdown","metadata":{"id":"3OaOo1UieotH"},"source":["# **Lấy features cho 1 video**"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"CKg7jqXC7iqY","executionInfo":{"status":"ok","timestamp":1686212314563,"user_tz":-420,"elapsed":4,"user":{"displayName":"nguyen toan","userId":"14848113097500887617"}}},"outputs":[],"source":["def handle_video_features(video_path, timestep, X_all, Y_all):\n","    cap = cv2.VideoCapture(video_path)\n","    X = []\n","    # Loop through the video frames-pip install protobuf==3.20.*\n","    count = 0\n","    label = 1 if 'fall' in video_path else 0\n","    while cap.isOpened():\n","        # Read a frame from the video\n","        success, frame = cap.read()\n","        if not success:\n","            break\n","        # Run YOLOv8 inference on the frame\n","        results = modelYOLO(frame)\n","        # If not exist person\n","        if results[0].masks is None:\n","            continue\n","        h, w, c = frame.shape\n","\n","        s = h * w\n","\n","        # get box object\n","        box = results[0].boxes[0].xyxy[0]\n","        box = box.cpu().numpy().astype(int)\n","        x1, y1, x2, y2 = box\n","\n","        # s = abs(x1 - x2) * abs(y1 - y2)\n","\n","        # background subtraction\n","        mask = (results[0].masks.data[0].cpu().numpy() * 255).astype('uint8')\n","        # resize size mask equal size original frame\n","        mask = cv2.resize(mask, (frame.shape[1], frame.shape[0]))\n","        # get bounding box person\n","        mask = mask[y1:y2, x1:x2]\n","        if len(X) < timestep:\n","            X.append(get_feature(mask, s))\n","        else:\n","            X = X[1:] + [get_feature(mask, s)]\n","            \n","            X_all.append(X)\n","            Y_all.append(label)\n","\n","        if cv2.waitKey(1) == ord('q'):\n","            break\n","      "]},{"cell_type":"markdown","metadata":{"id":"Oeu6o74Ceqxw"},"source":["# **Lấy features cho tập dataset**"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"NHeOqcca7k0y","executionInfo":{"status":"ok","timestamp":1686203688120,"user_tz":-420,"elapsed":3,"user":{"displayName":"nguyen toan","userId":"14848113097500887617"}}},"outputs":[],"source":["def create_dataset_feature(videos, number_frame_of_observation):\n","    X_all, Y_all = [], []\n","    # Duyệt qua tất cả các tệp trong thư mục\n","    for video in videos:\n","        handle_video_features(video, number_frame_of_observation, X_all, Y_all)\n","    save_to_npy(f'_Top-down-Framework/features/features_{number_frame_of_observation}frames.npy', np.array(X_all))\n","    save_to_npy(f'_Top-down-Framework/features/labels_{number_frame_of_observation}frames.npy', np.array(Y_all))"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"FA3GDLIQ7muZ","executionInfo":{"status":"ok","timestamp":1686203690720,"user_tz":-420,"elapsed":880,"user":{"displayName":"nguyen toan","userId":"14848113097500887617"}}},"outputs":[],"source":["modelYOLO = YOLO('_Top-down-Framework/best.pt')"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4004,"status":"ok","timestamp":1686203695445,"user":{"displayName":"nguyen toan","userId":"14848113097500887617"},"user_tz":-420},"id":"DYl4o10wEjxK","outputId":"be72ed54-36ca-4742-8ae9-e9108f899baa"},"outputs":[{"output_type":"stream","name":"stdout","text":["430\n"]}],"source":["videos = get_list_video()\n","random.Random(28).shuffle(videos)\n","\n","print(len(videos))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1640568,"status":"ok","timestamp":1686205338191,"user":{"displayName":"nguyen toan","userId":"14848113097500887617"},"user_tz":-420},"id":"rHDFnL7M8kV5","outputId":"d3908a50-48a7-4b2d-ed64-3a9a7fb84b13"},"outputs":[{"output_type":"stream","name":"stdout","text":["40\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[1;30;43mKết quả truyền trực tuyến bị cắt bớt đến 5000 dòng cuối.\u001b[0m\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.4ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 4.3ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.5ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.3ms\n","Speed: 1.5ms preprocess, 8.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.8ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 1.9ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 16.6ms\n","Speed: 1.6ms preprocess, 16.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.1ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.3ms\n","Speed: 2.6ms preprocess, 8.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 2.0ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.8ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.8ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 1.6ms preprocess, 10.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 1.9ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.7ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.6ms\n","Speed: 1.6ms preprocess, 12.6ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.9ms\n","Speed: 1.3ms preprocess, 11.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.4ms preprocess, 8.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 17.2ms\n","Speed: 1.6ms preprocess, 17.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 12.8ms\n","Speed: 1.5ms preprocess, 12.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 3 persons, 10.5ms\n","Speed: 1.5ms preprocess, 10.5ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 11.1ms\n","Speed: 1.5ms preprocess, 11.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 10.1ms\n","Speed: 1.4ms preprocess, 10.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 12.8ms\n","Speed: 1.4ms preprocess, 12.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.3ms preprocess, 10.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.3ms\n","Speed: 1.7ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.5ms preprocess, 10.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.9ms\n","Speed: 1.3ms preprocess, 12.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 3.0ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.0ms\n","Speed: 1.5ms preprocess, 11.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.4ms preprocess, 8.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 3.0ms preprocess, 9.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.5ms preprocess, 9.3ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.1ms\n","Speed: 1.4ms preprocess, 14.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.5ms\n","Speed: 1.5ms preprocess, 13.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.2ms\n","Speed: 3.0ms preprocess, 11.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.0ms\n","Speed: 1.6ms preprocess, 14.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.9ms\n","Speed: 1.3ms preprocess, 10.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.8ms\n","Speed: 1.4ms preprocess, 12.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 1.5ms preprocess, 10.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.0ms\n","Speed: 1.3ms preprocess, 13.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 13.4ms\n","Speed: 1.3ms preprocess, 13.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.5ms\n","Speed: 1.3ms preprocess, 9.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 8.6ms\n","Speed: 1.4ms preprocess, 8.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 10.1ms\n","Speed: 1.5ms preprocess, 10.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.8ms\n","Speed: 1.3ms preprocess, 9.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.1ms\n","Speed: 1.3ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 10.1ms\n","Speed: 1.4ms preprocess, 10.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 10.1ms\n","Speed: 1.6ms preprocess, 10.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.2ms\n","Speed: 1.2ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.3ms\n","Speed: 1.3ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.6ms\n","Speed: 1.5ms preprocess, 9.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.0ms\n","Speed: 1.3ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.8ms\n","Speed: 1.3ms preprocess, 9.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 11.0ms\n","Speed: 1.4ms preprocess, 11.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 10.8ms\n","Speed: 1.3ms preprocess, 10.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.0ms\n","Speed: 1.7ms preprocess, 9.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.3ms\n","Speed: 1.3ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.2ms\n","Speed: 1.4ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.0ms\n","Speed: 1.4ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 12.9ms\n","Speed: 1.5ms preprocess, 12.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 11.7ms\n","Speed: 1.4ms preprocess, 11.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 8.4ms\n","Speed: 1.3ms preprocess, 8.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.5ms\n","Speed: 1.3ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.4ms preprocess, 10.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.4ms preprocess, 9.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.6ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.6ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.9ms\n","Speed: 1.4ms preprocess, 13.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.7ms preprocess, 9.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.4ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.5ms preprocess, 9.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.3ms preprocess, 9.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.5ms\n","Speed: 1.4ms preprocess, 9.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 11.2ms\n","Speed: 1.5ms preprocess, 11.2ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 (no detections), 8.9ms\n","Speed: 1.6ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 (no detections), 10.8ms\n","Speed: 1.3ms preprocess, 10.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.1ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 20.3ms\n","Speed: 1.6ms preprocess, 20.3ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 17.6ms\n","Speed: 1.4ms preprocess, 17.6ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.9ms\n","Speed: 1.2ms preprocess, 13.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 1.5ms preprocess, 10.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 2.0ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.3ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.4ms\n","Speed: 1.6ms preprocess, 8.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.4ms\n","Speed: 1.5ms preprocess, 8.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.2ms\n","Speed: 2.9ms preprocess, 11.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.7ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.9ms preprocess, 8.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.3ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.9ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.3ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.9ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 2.0ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.3ms\n","Speed: 4.6ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 2.0ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.4ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.8ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.3ms\n","Speed: 2.4ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.9ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.2ms\n","Speed: 1.3ms preprocess, 11.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.2ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.7ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.2ms\n","Speed: 1.5ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 2.1ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.9ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 2.3ms preprocess, 10.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.8ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.9ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.9ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.4ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.9ms preprocess, 9.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.7ms\n","Speed: 1.4ms preprocess, 11.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 2.9ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.2ms\n","Speed: 1.8ms preprocess, 13.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.9ms preprocess, 10.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.8ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.3ms\n","Speed: 1.3ms preprocess, 8.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.3ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 2.0ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.5ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.4ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 2.4ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.3ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.6ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 1.3ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.2ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.3ms\n","Speed: 2.0ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 1.2ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.9ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.6ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.3ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.5ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.0ms preprocess, 8.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.4ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 1.3ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 2.1ms preprocess, 8.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 2.0ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 15.1ms\n","Speed: 1.4ms preprocess, 15.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.6ms\n","Speed: 1.4ms preprocess, 11.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.3ms preprocess, 10.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.9ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.8ms preprocess, 9.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.6ms preprocess, 9.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.1ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.9ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.9ms preprocess, 9.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.9ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 2.2ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 2.0ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.4ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 3.1ms preprocess, 10.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.2ms\n","Speed: 2.2ms preprocess, 11.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.5ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.2ms preprocess, 9.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 4.0ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 2.0ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.7ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 2.5ms preprocess, 8.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.4ms\n","Speed: 1.8ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 2.8ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.3ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.4ms preprocess, 8.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.3ms\n","Speed: 2.8ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 1.4ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 2.0ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.4ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.4ms\n","Speed: 2.7ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.9ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 2.2ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.8ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.1ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 2.1ms preprocess, 9.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.4ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.4ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 2.3ms preprocess, 10.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 1.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.4ms\n","Speed: 2.1ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.8ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 7.9ms\n","Speed: 3.0ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.9ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.4ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.3ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.0ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.9ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 2.0ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.9ms\n","Speed: 1.8ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 2.0ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 2.0ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 1.9ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.0ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.3ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 2.1ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 2.0ms preprocess, 10.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.1ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.5ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 7.7ms\n","Speed: 2.0ms preprocess, 7.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.8ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.6ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 2.1ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.2ms\n","Speed: 1.9ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.7ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.1ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.3ms\n","Speed: 2.8ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.0ms\n","Speed: 1.5ms preprocess, 12.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.9ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.7ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.7ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 2.1ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.1ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.0ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 1.4ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 2.9ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.4ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.4ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.3ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 1.3ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 2.0ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.7ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 2.0ms preprocess, 9.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.7ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.9ms preprocess, 9.1ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.2ms\n","Speed: 3.2ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.2ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.9ms\n","Speed: 1.8ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.4ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.9ms preprocess, 10.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.9ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.4ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.7ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 1.4ms preprocess, 8.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.9ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.9ms\n","Speed: 2.6ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.5ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.7ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 2.8ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 3.1ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 2.2ms preprocess, 10.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 3.1ms preprocess, 9.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.8ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.7ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.4ms\n","Speed: 2.2ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.5ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.8ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.5ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 2.1ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.2ms preprocess, 10.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.5ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.6ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.0ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.9ms\n","Speed: 1.5ms preprocess, 10.9ms inference, 7.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.1ms\n","Speed: 1.3ms preprocess, 14.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.3ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.0ms\n","Speed: 1.4ms preprocess, 11.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.5ms preprocess, 9.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.4ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.0ms\n","Speed: 1.4ms preprocess, 12.0ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 2.1ms preprocess, 8.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.4ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.0ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.2ms\n","Speed: 1.8ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 2.8ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.3ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 2.6ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.4ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 2.1ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.9ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.9ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.6ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 2.8ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.7ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.9ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.4ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.4ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.4ms\n","Speed: 1.7ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 1.9ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.7ms preprocess, 9.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 2.2ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.0ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.8ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 7.8ms\n","Speed: 1.3ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.5ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.4ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.3ms\n","Speed: 3.0ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 1.5ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.9ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.7ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.4ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.9ms\n","Speed: 1.9ms preprocess, 11.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.8ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.3ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.4ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.6ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.7ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.5ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.2ms\n","Speed: 2.5ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 2.1ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.7ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.4ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.4ms\n","Speed: 2.1ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 3.1ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.1ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.4ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.5ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.9ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.9ms\n","Speed: 1.5ms preprocess, 10.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 1.4ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.4ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.4ms\n","Speed: 3.2ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.9ms preprocess, 10.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.9ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.4ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.4ms\n","Speed: 1.6ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 2.8ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.5ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.3ms preprocess, 8.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.9ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.6ms preprocess, 10.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.7ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 2.2ms preprocess, 10.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.5ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.3ms\n","Speed: 1.4ms preprocess, 12.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.0ms\n","Speed: 1.8ms preprocess, 12.0ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.8ms\n","Speed: 1.4ms preprocess, 10.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.9ms preprocess, 10.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 15.3ms\n","Speed: 3.4ms preprocess, 15.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.7ms preprocess, 8.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.4ms preprocess, 9.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 15.5ms\n","Speed: 1.5ms preprocess, 15.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.3ms\n","Speed: 1.8ms preprocess, 13.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 4.7ms preprocess, 8.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 1.6ms preprocess, 8.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.7ms preprocess, 9.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.7ms preprocess, 9.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.4ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.6ms\n","Speed: 1.4ms preprocess, 11.6ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.4ms preprocess, 9.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.4ms preprocess, 8.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.4ms preprocess, 9.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.0ms\n","Speed: 1.4ms preprocess, 14.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.7ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.3ms preprocess, 10.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.6ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.6ms preprocess, 9.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.5ms preprocess, 8.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.3ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.4ms preprocess, 8.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.2ms preprocess, 9.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.3ms preprocess, 8.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.4ms preprocess, 9.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.4ms preprocess, 10.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.9ms\n","Speed: 1.4ms preprocess, 12.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.6ms\n","Speed: 1.4ms preprocess, 12.6ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.7ms\n","Speed: 1.4ms preprocess, 11.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.0ms\n","Speed: 1.2ms preprocess, 12.0ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 2.2ms preprocess, 9.2ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.5ms\n","Speed: 1.4ms preprocess, 11.5ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.1ms\n","Speed: 1.5ms preprocess, 13.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.9ms preprocess, 9.0ms inference, 9.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.6ms\n","Speed: 1.5ms preprocess, 14.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.4ms preprocess, 10.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.4ms preprocess, 9.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.3ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.4ms preprocess, 8.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.3ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.3ms\n","Speed: 1.3ms preprocess, 11.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.4ms\n","Speed: 1.3ms preprocess, 12.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.4ms preprocess, 10.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.9ms\n","Speed: 1.5ms preprocess, 11.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.3ms\n","Speed: 1.2ms preprocess, 8.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.5ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.8ms\n","Speed: 1.4ms preprocess, 10.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.6ms preprocess, 10.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.5ms\n","Speed: 1.4ms preprocess, 12.5ms inference, 6.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.7ms\n","Speed: 1.6ms preprocess, 13.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.3ms\n","Speed: 1.4ms preprocess, 13.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.0ms\n","Speed: 1.4ms preprocess, 12.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.3ms preprocess, 10.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 3.7ms preprocess, 8.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.3ms preprocess, 10.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.1ms\n","Speed: 1.5ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.2ms\n","Speed: 1.5ms preprocess, 12.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.2ms\n","Speed: 1.4ms preprocess, 12.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.4ms preprocess, 9.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.8ms\n","Speed: 1.4ms preprocess, 12.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.5ms\n","Speed: 1.4ms preprocess, 11.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.5ms preprocess, 8.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.4ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 19.0ms\n","Speed: 1.5ms preprocess, 19.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.3ms preprocess, 8.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 15.2ms\n","Speed: 2.0ms preprocess, 15.2ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.3ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.5ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 1.3ms preprocess, 8.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.0ms\n","Speed: 1.4ms preprocess, 11.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.3ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.3ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.4ms\n","Speed: 1.4ms preprocess, 13.4ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 1.3ms preprocess, 8.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.7ms\n","Speed: 1.3ms preprocess, 13.7ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.3ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.9ms\n","Speed: 1.4ms preprocess, 10.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.3ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 20.3ms\n","Speed: 1.4ms preprocess, 20.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.5ms\n","Speed: 1.3ms preprocess, 14.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.5ms preprocess, 9.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 1.5ms preprocess, 10.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.4ms\n","Speed: 1.3ms preprocess, 11.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.9ms\n","Speed: 2.5ms preprocess, 13.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.0ms\n","Speed: 1.3ms preprocess, 13.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 1.4ms preprocess, 8.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.8ms\n","Speed: 1.4ms preprocess, 12.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.3ms preprocess, 9.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.8ms\n","Speed: 1.3ms preprocess, 10.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.5ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 19.0ms\n","Speed: 1.3ms preprocess, 19.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.3ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 16.4ms\n","Speed: 1.4ms preprocess, 16.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.4ms preprocess, 9.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.7ms\n","Speed: 1.5ms preprocess, 11.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.5ms preprocess, 9.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.1ms\n","Speed: 6.1ms preprocess, 14.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.8ms\n","Speed: 1.5ms preprocess, 12.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.3ms preprocess, 10.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.5ms preprocess, 8.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.2ms\n","Speed: 1.5ms preprocess, 14.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.4ms preprocess, 8.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.0ms\n","Speed: 6.7ms preprocess, 13.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 3.0ms preprocess, 9.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.3ms preprocess, 9.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.6ms\n","Speed: 1.4ms preprocess, 12.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.4ms preprocess, 8.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 1.3ms preprocess, 10.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.4ms preprocess, 8.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.2ms\n","Speed: 1.4ms preprocess, 11.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.8ms\n","Speed: 1.5ms preprocess, 13.8ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.4ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.9ms\n","Speed: 3.0ms preprocess, 10.9ms inference, 6.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.7ms\n","Speed: 1.4ms preprocess, 13.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.8ms\n","Speed: 1.4ms preprocess, 10.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.3ms preprocess, 9.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.6ms\n","Speed: 1.4ms preprocess, 13.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.0ms\n","Speed: 1.4ms preprocess, 11.0ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.3ms\n","Speed: 1.5ms preprocess, 11.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.5ms preprocess, 10.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.3ms\n","Speed: 1.4ms preprocess, 12.3ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.2ms\n","Speed: 1.5ms preprocess, 12.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.7ms\n","Speed: 1.4ms preprocess, 14.7ms inference, 6.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.3ms preprocess, 9.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.9ms\n","Speed: 7.0ms preprocess, 14.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.4ms preprocess, 10.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.3ms\n","Speed: 1.4ms preprocess, 13.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.6ms\n","Speed: 2.5ms preprocess, 12.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.0ms\n","Speed: 1.4ms preprocess, 12.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 2.2ms preprocess, 10.6ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.8ms\n","Speed: 1.5ms preprocess, 10.8ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.1ms\n","Speed: 1.4ms preprocess, 13.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.8ms\n","Speed: 1.4ms preprocess, 13.8ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 15.0ms\n","Speed: 1.5ms preprocess, 15.0ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.4ms\n","Speed: 1.5ms preprocess, 13.4ms inference, 6.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.8ms\n","Speed: 1.4ms preprocess, 14.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.4ms preprocess, 10.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.3ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.5ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.4ms preprocess, 9.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.5ms preprocess, 10.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.3ms preprocess, 9.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 1.5ms preprocess, 8.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.1ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.6ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.7ms preprocess, 9.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.4ms\n","Speed: 1.6ms preprocess, 13.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.2ms\n","Speed: 1.6ms preprocess, 8.2ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 1.7ms preprocess, 8.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.3ms preprocess, 9.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.3ms\n","Speed: 1.6ms preprocess, 11.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.3ms preprocess, 10.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.4ms preprocess, 10.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.6ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 4.2ms preprocess, 8.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.7ms preprocess, 9.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 3.3ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.0ms\n","Speed: 8.2ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.3ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 1.4ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.6ms\n","Speed: 1.4ms preprocess, 12.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.8ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.7ms\n","Speed: 1.9ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.4ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.5ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.4ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.9ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.3ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.9ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.3ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.3ms\n","Speed: 2.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 3.7ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.8ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.9ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.4ms\n","Speed: 1.7ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.9ms preprocess, 9.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.7ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.3ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.0ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.8ms\n","Speed: 1.3ms preprocess, 10.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.3ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.9ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.9ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.9ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.5ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.2ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.3ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.3ms preprocess, 9.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.6ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 1.6ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.3ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.3ms\n","Speed: 1.4ms preprocess, 8.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.4ms\n","Speed: 1.1ms preprocess, 8.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.4ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.4ms preprocess, 8.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.4ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.3ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.0ms\n","Speed: 1.4ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.9ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 7.7ms\n","Speed: 2.0ms preprocess, 7.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.9ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.2ms\n","Speed: 2.8ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 1.5ms preprocess, 10.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.1ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.6ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.8ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.9ms\n","Speed: 1.6ms preprocess, 11.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.5ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.3ms preprocess, 9.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.6ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 1.6ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.1ms preprocess, 9.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.9ms preprocess, 9.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 2.0ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.4ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 2.1ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.4ms\n","Speed: 3.7ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 2.0ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.0ms\n","Speed: 2.5ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.6ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.6ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 2.0ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.2ms\n","Speed: 1.7ms preprocess, 13.2ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.4ms\n","Speed: 1.3ms preprocess, 8.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.4ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 2.2ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.3ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.7ms preprocess, 9.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.9ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.8ms preprocess, 9.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.3ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.4ms\n","Speed: 1.3ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 2.1ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.4ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.2ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.4ms preprocess, 10.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.4ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.5ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.8ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.9ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.7ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.9ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.7ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.6ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.3ms\n","Speed: 1.4ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.5ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 2.7ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.3ms preprocess, 9.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.4ms preprocess, 10.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 1.3ms preprocess, 10.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.3ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.7ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.7ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 1.3ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 7.9ms\n","Speed: 5.5ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.5ms\n","Speed: 1.3ms preprocess, 11.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 2.1ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.2ms\n","Speed: 1.3ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.8ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 1.5ms preprocess, 10.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.3ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.4ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.0ms\n","Speed: 1.9ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.4ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 1.3ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.4ms preprocess, 8.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.3ms\n","Speed: 1.3ms preprocess, 8.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 1.5ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.1ms\n","Speed: 1.4ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.3ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 2.2ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.8ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 7.9ms\n","Speed: 1.9ms preprocess, 7.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.3ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.4ms\n","Speed: 1.5ms preprocess, 8.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.3ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.3ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.3ms preprocess, 10.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 2.3ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.6ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.4ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.5ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.0ms preprocess, 9.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.6ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 2.1ms preprocess, 8.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.5ms preprocess, 9.5ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.8ms preprocess, 10.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.7ms\n","Speed: 1.5ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.4ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.8ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.1ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 2.0ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.5ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.4ms\n","Speed: 1.3ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.0ms\n","Speed: 1.9ms preprocess, 12.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.1ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.2ms\n","Speed: 1.5ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.1ms\n","Speed: 1.2ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.7ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 2.1ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.4ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 3.0ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 2.5ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.5ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.4ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.6ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.2ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.4ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 2.3ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 2.3ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 2.2ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.3ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.1ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.3ms\n","Speed: 1.5ms preprocess, 13.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.4ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.8ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.0ms\n","Speed: 1.9ms preprocess, 12.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.4ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.4ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.4ms preprocess, 9.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.4ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 2.7ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 1.2ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 1.3ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.1ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 3.0ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 1.3ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.7ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.4ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 2.2ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.3ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 1.2ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.9ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.3ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.3ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 2.1ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.9ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.0ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 2.0ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.2ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.3ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.3ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.2ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.0ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 2.0ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.3ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.3ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.0ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.3ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.7ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 2.2ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 2.6ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.2ms\n","Speed: 1.6ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.2ms\n","Speed: 1.3ms preprocess, 11.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.4ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.2ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 2.9ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.9ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.3ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 2.1ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.9ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.3ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.9ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.0ms\n","Speed: 1.5ms preprocess, 11.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.5ms\n","Speed: 1.7ms preprocess, 13.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.0ms\n","Speed: 1.3ms preprocess, 12.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.7ms\n","Speed: 2.6ms preprocess, 12.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.6ms\n","Speed: 1.5ms preprocess, 13.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.4ms preprocess, 9.9ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.2ms\n","Speed: 1.4ms preprocess, 12.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.0ms\n","Speed: 1.5ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 15.6ms\n","Speed: 1.4ms preprocess, 15.6ms inference, 6.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 2.3ms preprocess, 10.1ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.5ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.3ms preprocess, 9.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.8ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.3ms preprocess, 8.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.3ms preprocess, 8.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 1.3ms preprocess, 8.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.3ms preprocess, 9.5ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.3ms preprocess, 8.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.3ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.3ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.8ms\n","Speed: 1.4ms preprocess, 13.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.2ms\n","Speed: 1.4ms preprocess, 11.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.3ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.1ms\n","Speed: 1.4ms preprocess, 14.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.4ms preprocess, 9.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.2ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.0ms\n","Speed: 1.3ms preprocess, 13.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.7ms\n","Speed: 2.0ms preprocess, 11.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 2.1ms preprocess, 10.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.8ms\n","Speed: 1.3ms preprocess, 12.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.3ms preprocess, 9.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.3ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.4ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.3ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.3ms preprocess, 8.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.3ms preprocess, 10.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.0ms\n","Speed: 1.4ms preprocess, 12.0ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.4ms preprocess, 10.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.8ms\n","Speed: 1.4ms preprocess, 14.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.3ms preprocess, 10.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.2ms\n","Speed: 1.3ms preprocess, 14.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.6ms preprocess, 8.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.6ms\n","Speed: 1.3ms preprocess, 12.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.5ms\n","Speed: 1.7ms preprocess, 12.5ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.5ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 2.8ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.9ms\n","Speed: 1.3ms preprocess, 11.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 2.9ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.7ms preprocess, 9.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.2ms\n","Speed: 1.4ms preprocess, 11.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.2ms\n","Speed: 1.3ms preprocess, 12.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.4ms preprocess, 8.7ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.3ms preprocess, 9.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 2.9ms preprocess, 9.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.4ms preprocess, 8.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.9ms\n","Speed: 1.4ms preprocess, 10.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 1.3ms preprocess, 10.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 3.0ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.9ms\n","Speed: 1.5ms preprocess, 14.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.5ms preprocess, 9.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.4ms preprocess, 9.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.4ms preprocess, 9.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.3ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.4ms preprocess, 9.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.4ms preprocess, 10.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.5ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.4ms\n","Speed: 1.4ms preprocess, 12.4ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.6ms preprocess, 9.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 1.4ms preprocess, 10.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.4ms preprocess, 9.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 1.3ms preprocess, 10.5ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.6ms preprocess, 9.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.3ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.3ms\n","Speed: 1.6ms preprocess, 11.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.0ms\n","Speed: 1.6ms preprocess, 13.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.6ms\n","Speed: 1.6ms preprocess, 11.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.3ms preprocess, 9.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.3ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 15.6ms\n","Speed: 1.5ms preprocess, 15.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.4ms preprocess, 9.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.7ms\n","Speed: 1.7ms preprocess, 11.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 3.8ms preprocess, 9.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.1ms\n","Speed: 1.5ms preprocess, 11.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.8ms preprocess, 9.6ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 18.6ms\n","Speed: 1.5ms preprocess, 18.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 1.4ms preprocess, 10.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.5ms\n","Speed: 1.4ms preprocess, 11.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.5ms preprocess, 10.7ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 1.5ms preprocess, 10.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.5ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.3ms\n","Speed: 2.0ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 2.1ms preprocess, 10.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 2.0ms preprocess, 10.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.4ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 1.4ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.3ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 2.1ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 2.0ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.4ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.3ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.8ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.3ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.2ms\n","Speed: 1.3ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.0ms\n","Speed: 1.3ms preprocess, 12.0ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.9ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.8ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.3ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.3ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.3ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.3ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.1ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.7ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.3ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.0ms\n","Speed: 1.5ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 2.0ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 2.1ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 2.0ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.4ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 2.4ms preprocess, 9.5ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.8ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 2.4ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.8ms\n","Speed: 1.3ms preprocess, 10.8ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.8ms\n","Speed: 2.0ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 2.0ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.8ms\n","Speed: 1.3ms preprocess, 10.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 2.2ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.4ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 2.0ms preprocess, 10.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.9ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 2.0ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.9ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.0ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.1ms\n","Speed: 1.3ms preprocess, 8.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.4ms\n","Speed: 1.6ms preprocess, 8.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 1.9ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.7ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.4ms\n","Speed: 1.9ms preprocess, 8.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 3.0ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 2.0ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 2.0ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.4ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.4ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.3ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.9ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 1.2ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.1ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 1.3ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.3ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.6ms preprocess, 9.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.4ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.4ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.4ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.9ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.2ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.6ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.6ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 1.6ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 1.3ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.0ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.2ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.4ms preprocess, 10.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 2.0ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.3ms preprocess, 9.3ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.5ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.4ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 2.4ms preprocess, 10.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.4ms preprocess, 9.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.5ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 2.7ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 3.4ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.2ms\n","Speed: 6.0ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.8ms\n","Speed: 1.7ms preprocess, 10.8ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.7ms preprocess, 10.4ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.7ms preprocess, 8.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.6ms preprocess, 8.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.6ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.7ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.8ms preprocess, 9.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 1.5ms preprocess, 10.5ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 1.6ms preprocess, 8.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.4ms\n","Speed: 3.7ms preprocess, 8.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 1.2ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.3ms\n","Speed: 1.4ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.0ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 13.9ms\n","Speed: 2.2ms preprocess, 13.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.6ms\n","Speed: 2.2ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.7ms preprocess, 8.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 8.8ms\n","Speed: 1.6ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 10.4ms\n","Speed: 2.0ms preprocess, 10.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 11.7ms\n","Speed: 1.4ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.8ms\n","Speed: 1.3ms preprocess, 9.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.9ms\n","Speed: 1.9ms preprocess, 9.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.9ms\n","Speed: 1.5ms preprocess, 9.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.3ms\n","Speed: 3.3ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 10.3ms\n","Speed: 1.5ms preprocess, 10.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 8.6ms\n","Speed: 1.2ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.6ms\n","Speed: 1.9ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 8.4ms\n","Speed: 2.5ms preprocess, 8.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 3 persons, 10.0ms\n","Speed: 1.7ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.1ms\n","Speed: 1.4ms preprocess, 9.1ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 9.1ms\n","Speed: 1.7ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 2 persons, 10.2ms\n","Speed: 1.4ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.3ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.1ms\n","Speed: 1.8ms preprocess, 13.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.9ms\n","Speed: 2.1ms preprocess, 10.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.4ms\n","Speed: 1.8ms preprocess, 8.4ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.4ms\n","Speed: 1.6ms preprocess, 11.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.6ms preprocess, 9.3ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.7ms preprocess, 10.2ms inference, 9.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.9ms\n","Speed: 1.4ms preprocess, 13.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.8ms\n","Speed: 1.5ms preprocess, 11.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.3ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.4ms preprocess, 9.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.5ms preprocess, 10.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.4ms preprocess, 9.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.4ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.4ms preprocess, 8.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.5ms preprocess, 9.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.3ms\n","Speed: 1.3ms preprocess, 8.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 1.4ms preprocess, 8.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.3ms preprocess, 10.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.5ms preprocess, 9.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.5ms preprocess, 9.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 3.8ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.4ms preprocess, 8.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 2.0ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.0ms\n","Speed: 2.2ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.5ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.5ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.9ms\n","Speed: 1.5ms preprocess, 13.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.4ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.2ms\n","Speed: 1.3ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.3ms preprocess, 9.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 1.3ms preprocess, 8.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.3ms preprocess, 9.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.4ms preprocess, 9.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 3.3ms preprocess, 8.8ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 1.4ms preprocess, 8.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.0ms\n","Speed: 1.3ms preprocess, 11.0ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 3.5ms preprocess, 10.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.4ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.6ms preprocess, 8.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 2.9ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.5ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.6ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 2.0ms preprocess, 9.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.9ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.5ms preprocess, 9.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 2.2ms preprocess, 9.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 4.7ms preprocess, 9.4ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.7ms preprocess, 10.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.5ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 7.8ms\n","Speed: 1.8ms preprocess, 7.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.4ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.3ms\n","Speed: 1.5ms preprocess, 12.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.6ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.1ms\n","Speed: 1.5ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.1ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.0ms preprocess, 9.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.4ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.2ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 1.5ms preprocess, 10.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.2ms\n","Speed: 1.5ms preprocess, 8.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.4ms preprocess, 10.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.5ms preprocess, 9.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.4ms preprocess, 9.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.5ms preprocess, 8.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.5ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.7ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.5ms preprocess, 9.1ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.4ms preprocess, 8.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 6.3ms preprocess, 9.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.5ms preprocess, 9.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 2.9ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 1.4ms preprocess, 10.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.4ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.9ms\n","Speed: 1.9ms preprocess, 13.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 2.1ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.5ms preprocess, 9.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.6ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.3ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.5ms preprocess, 9.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.2ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.5ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.4ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.2ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.4ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.7ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.9ms preprocess, 9.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 2.1ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.6ms preprocess, 9.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.6ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.6ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.9ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 1.2ms preprocess, 10.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.0ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.6ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.4ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.7ms\n","Speed: 1.4ms preprocess, 11.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.9ms preprocess, 9.6ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.8ms\n","Speed: 1.5ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.2ms\n","Speed: 1.2ms preprocess, 11.2ms inference, 6.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.4ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.9ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 2.2ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.5ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.5ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.9ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.1ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.4ms\n","Speed: 3.9ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 2.2ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 2.2ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 2.0ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.4ms\n","Speed: 2.1ms preprocess, 11.4ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.7ms preprocess, 10.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.1ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.5ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.2ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.3ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.2ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 2.1ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.5ms preprocess, 9.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 2.3ms preprocess, 9.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 2.1ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.9ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 1.4ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.5ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.3ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.4ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.9ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.4ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.7ms\n","Speed: 2.0ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 2.3ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.2ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.7ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 3.9ms preprocess, 9.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.0ms preprocess, 9.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.9ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 2.8ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.2ms\n","Speed: 8.6ms preprocess, 13.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 18.0ms\n","Speed: 1.6ms preprocess, 18.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.5ms\n","Speed: 1.5ms preprocess, 11.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.5ms preprocess, 10.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 1.4ms preprocess, 10.5ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 1.5ms preprocess, 10.3ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.6ms preprocess, 9.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.4ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 1.3ms preprocess, 10.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.4ms preprocess, 10.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.3ms preprocess, 10.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.3ms preprocess, 8.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.4ms preprocess, 9.9ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.4ms\n","Speed: 5.7ms preprocess, 14.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.6ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.5ms\n","Speed: 1.5ms preprocess, 11.5ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.4ms\n","Speed: 1.5ms preprocess, 13.4ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.7ms preprocess, 9.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.2ms preprocess, 8.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.6ms preprocess, 8.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.4ms preprocess, 10.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.4ms preprocess, 10.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 1.4ms preprocess, 10.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.3ms preprocess, 8.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.3ms preprocess, 9.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 1.3ms preprocess, 8.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.5ms preprocess, 8.7ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.3ms preprocess, 9.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.3ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.5ms preprocess, 8.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.4ms preprocess, 8.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.1ms\n","Speed: 1.2ms preprocess, 8.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.6ms preprocess, 9.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.3ms preprocess, 9.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.9ms\n","Speed: 1.5ms preprocess, 10.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.3ms preprocess, 10.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.3ms preprocess, 10.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.9ms\n","Speed: 1.3ms preprocess, 12.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.5ms\n","Speed: 2.0ms preprocess, 11.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.3ms preprocess, 9.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.5ms\n","Speed: 1.4ms preprocess, 13.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.8ms\n","Speed: 1.4ms preprocess, 14.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.1ms\n","Speed: 2.9ms preprocess, 12.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.3ms\n","Speed: 3.0ms preprocess, 13.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.0ms\n","Speed: 1.3ms preprocess, 12.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 2.5ms preprocess, 9.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.1ms preprocess, 9.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.3ms preprocess, 9.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.7ms\n","Speed: 1.4ms preprocess, 12.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.3ms preprocess, 9.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.8ms\n","Speed: 1.5ms preprocess, 11.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 1.7ms preprocess, 8.6ms inference, 8.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.0ms\n","Speed: 1.3ms preprocess, 13.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.3ms preprocess, 9.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.4ms preprocess, 9.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 1.1ms preprocess, 8.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.3ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.4ms preprocess, 8.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.3ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.4ms preprocess, 10.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.4ms preprocess, 8.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 1.3ms preprocess, 10.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.4ms preprocess, 9.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.3ms\n","Speed: 1.3ms preprocess, 11.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.2ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.3ms preprocess, 9.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.3ms preprocess, 10.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 15.1ms\n","Speed: 3.2ms preprocess, 15.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 5.9ms preprocess, 8.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.9ms preprocess, 10.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.2ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.4ms preprocess, 10.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.2ms preprocess, 9.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.3ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 6.3ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.6ms preprocess, 9.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.3ms preprocess, 9.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.0ms\n","Speed: 1.3ms preprocess, 12.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.4ms preprocess, 9.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.0ms\n","Speed: 1.4ms preprocess, 13.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.0ms\n","Speed: 1.3ms preprocess, 11.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.3ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 1.2ms preprocess, 8.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.2ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.3ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.8ms\n","Speed: 1.4ms preprocess, 11.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.3ms preprocess, 10.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.8ms\n","Speed: 1.3ms preprocess, 14.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.2ms\n","Speed: 2.2ms preprocess, 13.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.3ms preprocess, 9.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 1.7ms preprocess, 8.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.3ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.5ms\n","Speed: 1.5ms preprocess, 12.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.5ms preprocess, 10.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.4ms\n","Speed: 2.8ms preprocess, 12.4ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.9ms\n","Speed: 1.3ms preprocess, 10.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.7ms\n","Speed: 1.3ms preprocess, 11.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 1.4ms preprocess, 10.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 1.4ms preprocess, 8.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.4ms preprocess, 9.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.1ms\n","Speed: 1.5ms preprocess, 13.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 15.7ms\n","Speed: 1.4ms preprocess, 15.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.1ms\n","Speed: 1.5ms preprocess, 13.1ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 16.1ms\n","Speed: 1.4ms preprocess, 16.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 16.1ms\n","Speed: 1.9ms preprocess, 16.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.7ms\n","Speed: 1.6ms preprocess, 12.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 2.6ms preprocess, 8.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.4ms preprocess, 10.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 1.4ms preprocess, 8.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.3ms preprocess, 8.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.5ms preprocess, 8.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.4ms preprocess, 9.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.6ms preprocess, 9.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.2ms preprocess, 9.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 2.1ms preprocess, 9.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 2.1ms preprocess, 9.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.4ms preprocess, 9.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.8ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.9ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 2.3ms preprocess, 10.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 2.1ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 2.0ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 3.4ms preprocess, 9.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.3ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.0ms\n","Speed: 1.6ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.3ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.9ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.4ms\n","Speed: 3.6ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.3ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.4ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.8ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.9ms\n","Speed: 2.0ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.4ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.2ms preprocess, 8.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.9ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 2.7ms preprocess, 10.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.6ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.5ms\n","Speed: 1.7ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.1ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.6ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.0ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 2.1ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.1ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.0ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 2.0ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.7ms\n","Speed: 2.0ms preprocess, 12.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.2ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.3ms preprocess, 10.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.3ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 2.0ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.8ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.9ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.2ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.9ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.9ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.3ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.2ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.3ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.3ms preprocess, 9.2ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.6ms\n","Speed: 1.3ms preprocess, 12.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.4ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.4ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.7ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 2.0ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.2ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 2.2ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.4ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 2.3ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 3.2ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.4ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.4ms preprocess, 9.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 1.7ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.8ms preprocess, 8.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 3.2ms preprocess, 9.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.6ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.5ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.8ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 3.1ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 2.1ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 2.4ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 1.5ms preprocess, 10.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 2.0ms preprocess, 10.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.3ms preprocess, 8.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 4.2ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 3.7ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 2.9ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 2.3ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 2.3ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.5ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 2.3ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.6ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.4ms preprocess, 9.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.5ms preprocess, 8.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 1.7ms preprocess, 10.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.5ms preprocess, 8.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.7ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.6ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 1.4ms preprocess, 8.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.3ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.4ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.3ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.4ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.4ms\n","Speed: 2.0ms preprocess, 8.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.2ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.5ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.6ms\n","Speed: 1.6ms preprocess, 12.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.7ms preprocess, 9.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 3.1ms preprocess, 10.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.2ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.5ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.9ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.5ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 1.5ms preprocess, 10.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.4ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.4ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.3ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.4ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.5ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.7ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.6ms\n","Speed: 2.3ms preprocess, 13.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 2.3ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.1ms\n","Speed: 2.5ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.9ms\n","Speed: 1.6ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 2.1ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 2.2ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.6ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.6ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.6ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 2.4ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.6ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 2.3ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.0ms\n","Speed: 2.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 2.0ms preprocess, 9.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.9ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.5ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.5ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.3ms preprocess, 9.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.3ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.2ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.5ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.3ms preprocess, 10.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 3.6ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.5ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 2.1ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.5ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.0ms\n","Speed: 1.4ms preprocess, 12.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.0ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.0ms\n","Speed: 1.8ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.9ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 2.0ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.3ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.2ms\n","Speed: 1.2ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 2.1ms preprocess, 9.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 2.9ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.3ms preprocess, 10.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.1ms\n","Speed: 1.6ms preprocess, 12.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 2.2ms preprocess, 10.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 2.0ms preprocess, 10.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 7.8ms\n","Speed: 2.2ms preprocess, 7.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.0ms\n","Speed: 1.5ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 2.2ms preprocess, 10.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.6ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.4ms\n","Speed: 2.1ms preprocess, 11.4ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 2.7ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.9ms\n","Speed: 1.4ms preprocess, 10.9ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.7ms preprocess, 9.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.7ms preprocess, 9.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.6ms\n","Speed: 1.4ms preprocess, 11.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 3.5ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 1.5ms preprocess, 10.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.2ms\n","Speed: 1.5ms preprocess, 11.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.2ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.6ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.5ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.8ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.4ms preprocess, 9.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.0ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.3ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.3ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.7ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.4ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.5ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.8ms\n","Speed: 1.9ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.3ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.5ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.1ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.4ms preprocess, 9.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.8ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.9ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.9ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.5ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.2ms preprocess, 9.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.3ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.4ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 2.3ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 2.9ms preprocess, 9.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 2.5ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.6ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.3ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.0ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 2.0ms preprocess, 8.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 2.0ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.5ms preprocess, 8.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.2ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.6ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 2.1ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.1ms\n","Speed: 2.2ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 2.2ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.9ms preprocess, 10.7ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.3ms\n","Speed: 1.4ms preprocess, 11.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.1ms\n","Speed: 1.4ms preprocess, 8.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.4ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 2.0ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 1.3ms preprocess, 8.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.0ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.0ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.2ms\n","Speed: 1.2ms preprocess, 8.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.3ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 2.0ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 2.0ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.3ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.4ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.2ms\n","Speed: 1.5ms preprocess, 12.2ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.5ms\n","Speed: 1.4ms preprocess, 13.5ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.2ms\n","Speed: 1.5ms preprocess, 13.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.7ms\n","Speed: 1.9ms preprocess, 11.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.8ms\n","Speed: 3.0ms preprocess, 12.8ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.7ms preprocess, 10.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.7ms\n","Speed: 1.6ms preprocess, 13.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.7ms\n","Speed: 1.6ms preprocess, 13.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 17.7ms\n","Speed: 1.5ms preprocess, 17.7ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 3.0ms preprocess, 9.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 2.7ms preprocess, 8.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 1.3ms preprocess, 10.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.7ms\n","Speed: 1.4ms preprocess, 12.7ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.6ms\n","Speed: 1.5ms preprocess, 11.6ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.2ms\n","Speed: 1.3ms preprocess, 12.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.8ms preprocess, 9.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.4ms preprocess, 9.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.4ms preprocess, 9.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.2ms\n","Speed: 1.3ms preprocess, 14.2ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.3ms\n","Speed: 1.4ms preprocess, 12.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.3ms\n","Speed: 1.3ms preprocess, 11.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.2ms preprocess, 8.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.2ms preprocess, 10.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.3ms preprocess, 10.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 1.4ms preprocess, 10.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.4ms\n","Speed: 1.2ms preprocess, 13.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.1ms\n","Speed: 1.6ms preprocess, 12.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 1.6ms preprocess, 10.5ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.6ms\n","Speed: 1.5ms preprocess, 11.6ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.1ms\n","Speed: 1.5ms preprocess, 11.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.4ms\n","Speed: 1.4ms preprocess, 11.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.3ms\n","Speed: 1.3ms preprocess, 12.3ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.9ms\n","Speed: 1.5ms preprocess, 11.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 2.2ms preprocess, 10.7ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.4ms preprocess, 9.2ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.4ms preprocess, 10.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.3ms preprocess, 9.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.4ms\n","Speed: 1.3ms preprocess, 11.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.5ms\n","Speed: 1.5ms preprocess, 12.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.9ms\n","Speed: 1.4ms preprocess, 10.9ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.1ms\n","Speed: 1.3ms preprocess, 13.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.3ms\n","Speed: 1.5ms preprocess, 14.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.6ms preprocess, 9.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.3ms preprocess, 10.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.5ms preprocess, 9.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.5ms\n","Speed: 1.5ms preprocess, 12.5ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 3.2ms preprocess, 9.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.4ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.2ms\n","Speed: 1.3ms preprocess, 8.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.8ms\n","Speed: 1.6ms preprocess, 12.8ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.6ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 3.5ms preprocess, 9.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.3ms\n","Speed: 1.3ms preprocess, 14.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.5ms\n","Speed: 1.4ms preprocess, 10.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 3.0ms preprocess, 8.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.5ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.7ms\n","Speed: 1.6ms preprocess, 14.7ms inference, 7.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 3.3ms preprocess, 9.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.3ms preprocess, 8.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.3ms\n","Speed: 1.6ms preprocess, 11.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.5ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.2ms\n","Speed: 1.4ms preprocess, 14.2ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 15.5ms\n","Speed: 1.4ms preprocess, 15.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.4ms preprocess, 10.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.5ms preprocess, 9.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.5ms preprocess, 9.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.7ms preprocess, 10.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.5ms\n","Speed: 1.5ms preprocess, 12.5ms inference, 6.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.3ms\n","Speed: 2.1ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.7ms\n","Speed: 1.6ms preprocess, 11.7ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.6ms\n","Speed: 1.5ms preprocess, 12.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.6ms\n","Speed: 1.7ms preprocess, 11.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.7ms\n","Speed: 1.5ms preprocess, 12.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.6ms preprocess, 10.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.5ms\n","Speed: 1.6ms preprocess, 11.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.0ms\n","Speed: 1.6ms preprocess, 11.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.4ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.7ms\n","Speed: 1.6ms preprocess, 8.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.9ms\n","Speed: 1.5ms preprocess, 11.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.7ms\n","Speed: 1.3ms preprocess, 12.7ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.3ms\n","Speed: 1.2ms preprocess, 11.3ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.2ms\n","Speed: 1.5ms preprocess, 12.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 16.6ms\n","Speed: 1.5ms preprocess, 16.6ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.3ms\n","Speed: 1.4ms preprocess, 12.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 17.9ms\n","Speed: 1.8ms preprocess, 17.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.6ms\n","Speed: 1.4ms preprocess, 12.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.5ms preprocess, 10.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.3ms\n","Speed: 1.4ms preprocess, 14.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 1.6ms preprocess, 10.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.9ms\n","Speed: 2.1ms preprocess, 10.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.0ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 2.0ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.5ms preprocess, 9.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.5ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.6ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 2.3ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 1.5ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.3ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.7ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 2.4ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 2.1ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.1ms\n","Speed: 2.0ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 5.4ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.1ms preprocess, 9.0ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.8ms\n","Speed: 2.0ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.9ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 1.4ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.3ms\n","Speed: 2.1ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 2.5ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.6ms\n","Speed: 2.3ms preprocess, 11.6ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.5ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.5ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.5ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.4ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.5ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.6ms preprocess, 9.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.9ms preprocess, 8.9ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.9ms\n","Speed: 1.6ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.8ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.1ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.1ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 1.4ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.9ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.4ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.4ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 2.1ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.6ms preprocess, 9.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.4ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.3ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.2ms\n","Speed: 1.4ms preprocess, 11.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.4ms\n","Speed: 2.0ms preprocess, 11.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.5ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.8ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.7ms preprocess, 9.9ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.5ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.2ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 2.1ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.4ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 2.0ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 3.1ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 1.6ms preprocess, 10.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 2.2ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.9ms\n","Speed: 1.4ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 2.0ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.3ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 2.0ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 3.5ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.0ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 2.1ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.4ms preprocess, 8.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 2.3ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.3ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 2.3ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.5ms\n","Speed: 1.4ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.6ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.5ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.3ms\n","Speed: 1.9ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.3ms\n","Speed: 2.4ms preprocess, 11.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.5ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.3ms\n","Speed: 1.5ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.9ms preprocess, 9.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.8ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.5ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.5ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.9ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.2ms\n","Speed: 2.0ms preprocess, 8.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.1ms preprocess, 9.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.3ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.8ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.2ms\n","Speed: 1.4ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.5ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 1.5ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.4ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 2.1ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.6ms\n","Speed: 1.4ms preprocess, 11.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 14.1ms\n","Speed: 1.4ms preprocess, 14.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.3ms\n","Speed: 1.6ms preprocess, 11.3ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.4ms\n","Speed: 1.6ms preprocess, 12.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.5ms preprocess, 9.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 1.5ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 3.0ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.8ms\n","Speed: 1.4ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.9ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.9ms\n","Speed: 2.4ms preprocess, 11.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 2.1ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 13.7ms\n","Speed: 2.3ms preprocess, 13.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.4ms\n","Speed: 1.6ms preprocess, 10.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 1.9ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 2.1ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 2.0ms preprocess, 9.5ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 3.0ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.3ms\n","Speed: 3.7ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 15.9ms\n","Speed: 2.2ms preprocess, 15.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.4ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 2.1ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.5ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 3.2ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 2.2ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.0ms\n","Speed: 1.4ms preprocess, 11.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.7ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.8ms preprocess, 10.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.5ms preprocess, 10.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 2.3ms preprocess, 8.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.7ms\n","Speed: 1.3ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.4ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.0ms\n","Speed: 2.3ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.8ms\n","Speed: 1.4ms preprocess, 8.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.3ms\n","Speed: 1.8ms preprocess, 8.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.6ms\n","Speed: 1.8ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.5ms\n","Speed: 1.7ms preprocess, 8.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.5ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.4ms preprocess, 8.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.5ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 15.2ms\n","Speed: 4.3ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 15.5ms\n","Speed: 1.4ms preprocess, 15.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 2.0ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 2.1ms preprocess, 9.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.4ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 2.1ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.2ms\n","Speed: 1.6ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 2.0ms preprocess, 10.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 2.0ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 3.1ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.0ms\n","Speed: 2.5ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.6ms\n","Speed: 1.4ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 2.4ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.8ms\n","Speed: 1.4ms preprocess, 11.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.5ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.7ms\n","Speed: 1.4ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.9ms\n","Speed: 3.2ms preprocess, 9.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.3ms\n","Speed: 1.5ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.5ms preprocess, 9.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.6ms preprocess, 9.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 8.9ms\n","Speed: 1.4ms preprocess, 8.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.4ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.5ms preprocess, 9.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 2.2ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.1ms\n","Speed: 1.4ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 1.4ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.5ms\n","Speed: 1.5ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 11.9ms\n","Speed: 1.4ms preprocess, 11.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 7.8ms\n","Speed: 1.8ms preprocess, 7.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 12.9ms\n","Speed: 1.6ms preprocess, 12.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.5ms preprocess, 9.6ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.4ms\n","Speed: 2.1ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 3.1ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.6ms\n","Speed: 1.9ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.2ms\n","Speed: 4.1ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.1ms\n","Speed: 1.9ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 10.8ms\n","Speed: 1.7ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 person, 9.8ms\n","Speed: 2.0ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"]}],"source":["for number_frame_of_observation in [40]:\n","  print(number_frame_of_observation)\n","  create_dataset_feature(videos, number_frame_of_observation)"]},{"cell_type":"markdown","metadata":{"id":"W23te6ede6y3"},"source":["# **Train model LSTM**"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"7tVV-KkKDCra","executionInfo":{"status":"ok","timestamp":1686212314563,"user_tz":-420,"elapsed":4,"user":{"displayName":"nguyen toan","userId":"14848113097500887617"}}},"outputs":[],"source":["def recall_m(y_true, y_pred):\n","    true_positives1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives1 = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall1 = true_positives1 / (possible_positives1 + K.epsilon())\n","\n","    return recall1\n","\n","def precision_m(y_true, y_pred):\n","    true_positives1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives1 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision1 = true_positives1 / (predicted_positives1 + K.epsilon())\n","\n","    return precision1\n","\n","def f1_m(y_true, y_pred):\n","    precision = precision_m(y_true, y_pred)\n","    recall = recall_m(y_true, y_pred)\n","\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"XWuAGRXrBrTo","executionInfo":{"status":"ok","timestamp":1686212314563,"user_tz":-420,"elapsed":4,"user":{"displayName":"nguyen toan","userId":"14848113097500887617"}}},"outputs":[],"source":["def trainLSTM(timestep, version):\n","  with open(f'/content/drive/MyDrive/PBL5/_Top-down-Framework/features/features_{timestep}frames.npy', \"rb\") as f:\n","    X = np.load(f)\n","    f.close()\n","  with open(f'/content/drive/MyDrive/PBL5/_Top-down-Framework/features/labels_{timestep}frames.npy', \"rb\") as f:\n","      y = np.load(f)\n","      f.close()\n","\n","\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n","  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=0, stratify=y_train)\n","  save_to_npy(f'_Top-down-Framework/features/train/features_{timestep}frames_train_v{version}', X_train)\n","  save_to_npy(f'_Top-down-Framework/features/train/labels_{timestep}frames_train_v{version}', y_train)\n","  save_to_npy(f'_Top-down-Framework/features/val/features_{timestep}frames_val_v{version}', X_val)\n","  save_to_npy(f'_Top-down-Framework/features/val/labels_{timestep}frames_val_v{version}', y_val)\n","  save_to_npy(f'_Top-down-Framework/features/test/features_{timestep}frames_test_v{version}', X_test)\n","  save_to_npy(f'_Top-down-Framework/features/test/labels_{timestep}frames_test_v{version}', y_test)\n","\n","  modelLSTM = Sequential() # Stacked LSTM\n","  modelLSTM.add(LSTM(units=50, return_sequences=True, input_shape=(timestep, 5)))\n","  modelLSTM.add(Dropout(0.2))\n","  modelLSTM.add(LSTM(units=50, return_sequences=True))\n","  modelLSTM.add(Dropout(0.2))\n","  modelLSTM.add(LSTM(units=50, return_sequences=True))\n","  modelLSTM.add(Dropout(0.2))\n","  modelLSTM.add(LSTM(units=50))\n","  modelLSTM.add(Dropout(0.2))\n","  modelLSTM.add(Dense(units=1, activation='sigmoid')) \n","  from keras.optimizers import Adam\n","  optimizer = Adam(learning_rate=0.001)\n","  modelLSTM.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', f1_m])\n","\n","\n","  csv_logger = CSVLogger(f'_Top-down-Framework/Result/{timestep}frames_v{version}/history.csv', append=True, separator=',')\n","  history = modelLSTM.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val, y_val), callbacks=[csv_logger])\n","  modelLSTM.save(f'/content/drive/MyDrive/PBL5/_Top-down-Framework/modelLSTM/model_lstm_{timestep}frames_v{version}.h5')\n","\n","\n","  # summarize history for accuracy\n","  plt.plot(history.history['accuracy'])\n","  plt.plot(history.history['val_accuracy'])\n","  plt.title('model accuracy')\n","  plt.ylabel('accuracy')\n","  plt.xlabel('epoch')\n","  plt.legend(['train', 'test'], loc='upper left')\n","  plt.savefig(f'_Top-down-Framework/Result/{timestep}frames_v{version}/accuracy.png')\n","  plt.close()\n","  # summarize history for loss\n","  plt.plot(history.history['loss'])\n","  plt.plot(history.history['val_loss'])\n","  plt.title('model loss')\n","  plt.ylabel('loss')\n","  plt.xlabel('epoch')\n","  plt.legend(['train', 'test'], loc='upper left')\n","  # plt.show()\n","  plt.savefig(f'_Top-down-Framework/Result/{timestep}frames_v{version}/loss.png')\n","  plt.close()\n","  # summarize history for f1\n","  plt.plot(history.history['f1_m'])\n","  plt.plot(history.history['val_f1_m'])\n","  plt.title('model f1')\n","  plt.ylabel('f1')\n","  plt.xlabel('epoch')\n","  plt.legend(['train', 'test'], loc='upper left')\n","  # plt.show()\n","  plt.savefig(f'_Top-down-Framework/Result/{timestep}frames_v{version}/f1.png')\n","  plt.close()"]},{"cell_type":"code","source":["for number_frame_of_observation in [30, 35, 40]:\n","  for version in [1, 2, 3]:\n","    print('Number frame of observation: {}, version: {}'.format(number_frame_of_observation, version))\n","    trainLSTM(number_frame_of_observation, version)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sn-HxjFFTSsj","executionInfo":{"status":"ok","timestamp":1686214736560,"user_tz":-420,"elapsed":2422001,"user":{"displayName":"nguyen toan","userId":"14848113097500887617"}},"outputId":"d7d57590-2635-4c0a-ef8e-6ffe2a14aaee"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Number frame of observation: 30, version: 1\n","Epoch 1/30\n","511/511 [==============================] - 33s 19ms/step - loss: 0.3451 - accuracy: 0.8648 - f1_m: 0.6577 - val_loss: 0.3031 - val_accuracy: 0.8791 - val_f1_m: 0.7145\n","Epoch 2/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.2851 - accuracy: 0.8921 - f1_m: 0.7518 - val_loss: 0.2936 - val_accuracy: 0.8937 - val_f1_m: 0.7311\n","Epoch 3/30\n","511/511 [==============================] - 7s 14ms/step - loss: 0.2628 - accuracy: 0.9028 - f1_m: 0.7745 - val_loss: 0.2672 - val_accuracy: 0.9001 - val_f1_m: 0.7455\n","Epoch 4/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.2431 - accuracy: 0.9080 - f1_m: 0.7889 - val_loss: 0.2528 - val_accuracy: 0.9053 - val_f1_m: 0.7880\n","Epoch 5/30\n","511/511 [==============================] - 7s 15ms/step - loss: 0.2234 - accuracy: 0.9174 - f1_m: 0.8131 - val_loss: 0.2243 - val_accuracy: 0.9224 - val_f1_m: 0.8230\n","Epoch 6/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.2085 - accuracy: 0.9250 - f1_m: 0.8300 - val_loss: 0.2141 - val_accuracy: 0.9207 - val_f1_m: 0.8191\n","Epoch 7/30\n","511/511 [==============================] - 8s 15ms/step - loss: 0.1960 - accuracy: 0.9300 - f1_m: 0.8436 - val_loss: 0.2049 - val_accuracy: 0.9263 - val_f1_m: 0.8219\n","Epoch 8/30\n","511/511 [==============================] - 8s 17ms/step - loss: 0.1812 - accuracy: 0.9335 - f1_m: 0.8498 - val_loss: 0.2005 - val_accuracy: 0.9314 - val_f1_m: 0.8352\n","Epoch 9/30\n","511/511 [==============================] - 8s 16ms/step - loss: 0.1654 - accuracy: 0.9414 - f1_m: 0.8727 - val_loss: 0.1762 - val_accuracy: 0.9348 - val_f1_m: 0.8458\n","Epoch 10/30\n","511/511 [==============================] - 7s 14ms/step - loss: 0.1588 - accuracy: 0.9440 - f1_m: 0.8755 - val_loss: 0.1560 - val_accuracy: 0.9451 - val_f1_m: 0.8756\n","Epoch 11/30\n","511/511 [==============================] - 12s 23ms/step - loss: 0.1453 - accuracy: 0.9483 - f1_m: 0.8889 - val_loss: 0.1505 - val_accuracy: 0.9498 - val_f1_m: 0.8864\n","Epoch 12/30\n","511/511 [==============================] - 8s 15ms/step - loss: 0.1343 - accuracy: 0.9555 - f1_m: 0.9013 - val_loss: 0.1296 - val_accuracy: 0.9601 - val_f1_m: 0.9126\n","Epoch 13/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.1198 - accuracy: 0.9594 - f1_m: 0.9135 - val_loss: 0.1239 - val_accuracy: 0.9554 - val_f1_m: 0.9060\n","Epoch 14/30\n","511/511 [==============================] - 8s 16ms/step - loss: 0.1133 - accuracy: 0.9618 - f1_m: 0.9179 - val_loss: 0.1491 - val_accuracy: 0.9507 - val_f1_m: 0.8980\n","Epoch 15/30\n","511/511 [==============================] - 8s 15ms/step - loss: 0.1004 - accuracy: 0.9667 - f1_m: 0.9256 - val_loss: 0.1227 - val_accuracy: 0.9593 - val_f1_m: 0.9102\n","Epoch 16/30\n","511/511 [==============================] - 8s 17ms/step - loss: 0.0942 - accuracy: 0.9695 - f1_m: 0.9354 - val_loss: 0.1005 - val_accuracy: 0.9661 - val_f1_m: 0.9282\n","Epoch 17/30\n","511/511 [==============================] - 7s 14ms/step - loss: 0.0890 - accuracy: 0.9718 - f1_m: 0.9348 - val_loss: 0.0933 - val_accuracy: 0.9704 - val_f1_m: 0.9387\n","Epoch 18/30\n","511/511 [==============================] - 9s 18ms/step - loss: 0.0784 - accuracy: 0.9743 - f1_m: 0.9454 - val_loss: 0.0846 - val_accuracy: 0.9696 - val_f1_m: 0.9371\n","Epoch 19/30\n","511/511 [==============================] - 7s 14ms/step - loss: 0.0794 - accuracy: 0.9743 - f1_m: 0.9461 - val_loss: 0.0815 - val_accuracy: 0.9717 - val_f1_m: 0.9432\n","Epoch 20/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.0685 - accuracy: 0.9769 - f1_m: 0.9479 - val_loss: 0.0803 - val_accuracy: 0.9726 - val_f1_m: 0.9449\n","Epoch 21/30\n","511/511 [==============================] - 8s 16ms/step - loss: 0.0699 - accuracy: 0.9763 - f1_m: 0.9486 - val_loss: 0.0614 - val_accuracy: 0.9773 - val_f1_m: 0.9530\n","Epoch 22/30\n","511/511 [==============================] - 8s 16ms/step - loss: 0.0612 - accuracy: 0.9783 - f1_m: 0.9536 - val_loss: 0.1401 - val_accuracy: 0.9498 - val_f1_m: 0.8915\n","Epoch 23/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.0573 - accuracy: 0.9817 - f1_m: 0.9603 - val_loss: 0.0527 - val_accuracy: 0.9846 - val_f1_m: 0.9677\n","Epoch 24/30\n","511/511 [==============================] - 7s 14ms/step - loss: 0.0531 - accuracy: 0.9830 - f1_m: 0.9623 - val_loss: 0.0597 - val_accuracy: 0.9790 - val_f1_m: 0.9560\n","Epoch 25/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.0421 - accuracy: 0.9855 - f1_m: 0.9706 - val_loss: 0.0429 - val_accuracy: 0.9837 - val_f1_m: 0.9703\n","Epoch 26/30\n","511/511 [==============================] - 7s 14ms/step - loss: 0.0463 - accuracy: 0.9846 - f1_m: 0.9687 - val_loss: 0.0356 - val_accuracy: 0.9880 - val_f1_m: 0.9759\n","Epoch 27/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.0382 - accuracy: 0.9864 - f1_m: 0.9699 - val_loss: 0.0504 - val_accuracy: 0.9837 - val_f1_m: 0.9667\n","Epoch 28/30\n","511/511 [==============================] - 8s 15ms/step - loss: 0.0413 - accuracy: 0.9862 - f1_m: 0.9693 - val_loss: 0.0658 - val_accuracy: 0.9794 - val_f1_m: 0.9576\n","Epoch 29/30\n","511/511 [==============================] - 8s 15ms/step - loss: 0.0390 - accuracy: 0.9869 - f1_m: 0.9737 - val_loss: 0.0395 - val_accuracy: 0.9884 - val_f1_m: 0.9763\n","Epoch 30/30\n","511/511 [==============================] - 8s 16ms/step - loss: 0.0365 - accuracy: 0.9881 - f1_m: 0.9761 - val_loss: 0.0344 - val_accuracy: 0.9863 - val_f1_m: 0.9716\n","Number frame of observation: 30, version: 2\n","Epoch 1/30\n","511/511 [==============================] - 17s 19ms/step - loss: 0.3453 - accuracy: 0.8646 - f1_m: 0.6670 - val_loss: 0.2782 - val_accuracy: 0.8873 - val_f1_m: 0.7404\n","Epoch 2/30\n","511/511 [==============================] - 8s 17ms/step - loss: 0.2892 - accuracy: 0.8900 - f1_m: 0.7409 - val_loss: 0.2784 - val_accuracy: 0.8873 - val_f1_m: 0.7696\n","Epoch 3/30\n","511/511 [==============================] - 7s 15ms/step - loss: 0.2650 - accuracy: 0.9000 - f1_m: 0.7711 - val_loss: 0.2387 - val_accuracy: 0.9130 - val_f1_m: 0.7979\n","Epoch 4/30\n","511/511 [==============================] - 9s 18ms/step - loss: 0.2409 - accuracy: 0.9089 - f1_m: 0.7937 - val_loss: 0.2183 - val_accuracy: 0.9190 - val_f1_m: 0.8078\n","Epoch 5/30\n","511/511 [==============================] - 7s 14ms/step - loss: 0.2290 - accuracy: 0.9142 - f1_m: 0.8042 - val_loss: 0.1944 - val_accuracy: 0.9331 - val_f1_m: 0.8566\n","Epoch 6/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.2101 - accuracy: 0.9220 - f1_m: 0.8238 - val_loss: 0.1887 - val_accuracy: 0.9323 - val_f1_m: 0.8498\n","Epoch 7/30\n","511/511 [==============================] - 7s 14ms/step - loss: 0.1898 - accuracy: 0.9316 - f1_m: 0.8481 - val_loss: 0.1733 - val_accuracy: 0.9374 - val_f1_m: 0.8601\n","Epoch 8/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.1749 - accuracy: 0.9378 - f1_m: 0.8599 - val_loss: 0.1705 - val_accuracy: 0.9374 - val_f1_m: 0.8600\n","Epoch 9/30\n","511/511 [==============================] - 8s 16ms/step - loss: 0.1639 - accuracy: 0.9422 - f1_m: 0.8706 - val_loss: 0.1929 - val_accuracy: 0.9293 - val_f1_m: 0.8555\n","Epoch 10/30\n","511/511 [==============================] - 8s 15ms/step - loss: 0.1546 - accuracy: 0.9454 - f1_m: 0.8821 - val_loss: 0.1382 - val_accuracy: 0.9516 - val_f1_m: 0.8938\n","Epoch 11/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.1336 - accuracy: 0.9517 - f1_m: 0.8940 - val_loss: 0.1308 - val_accuracy: 0.9550 - val_f1_m: 0.9018\n","Epoch 12/30\n","511/511 [==============================] - 8s 15ms/step - loss: 0.1311 - accuracy: 0.9528 - f1_m: 0.8992 - val_loss: 0.1244 - val_accuracy: 0.9584 - val_f1_m: 0.9101\n","Epoch 13/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.1116 - accuracy: 0.9604 - f1_m: 0.9167 - val_loss: 0.1249 - val_accuracy: 0.9563 - val_f1_m: 0.9065\n","Epoch 14/30\n","511/511 [==============================] - 8s 15ms/step - loss: 0.1102 - accuracy: 0.9615 - f1_m: 0.9154 - val_loss: 0.0939 - val_accuracy: 0.9661 - val_f1_m: 0.9290\n","Epoch 15/30\n","511/511 [==============================] - 8s 17ms/step - loss: 0.0894 - accuracy: 0.9680 - f1_m: 0.9323 - val_loss: 0.0786 - val_accuracy: 0.9764 - val_f1_m: 0.9498\n","Epoch 16/30\n","511/511 [==============================] - 8s 16ms/step - loss: 0.0872 - accuracy: 0.9700 - f1_m: 0.9378 - val_loss: 0.0724 - val_accuracy: 0.9747 - val_f1_m: 0.9453\n","Epoch 17/30\n","511/511 [==============================] - 8s 15ms/step - loss: 0.0790 - accuracy: 0.9742 - f1_m: 0.9466 - val_loss: 0.0617 - val_accuracy: 0.9769 - val_f1_m: 0.9491\n","Epoch 18/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.0734 - accuracy: 0.9740 - f1_m: 0.9449 - val_loss: 0.0540 - val_accuracy: 0.9841 - val_f1_m: 0.9677\n","Epoch 19/30\n","511/511 [==============================] - 8s 15ms/step - loss: 0.0676 - accuracy: 0.9768 - f1_m: 0.9506 - val_loss: 0.0571 - val_accuracy: 0.9811 - val_f1_m: 0.9596\n","Epoch 20/30\n","511/511 [==============================] - 9s 18ms/step - loss: 0.0623 - accuracy: 0.9781 - f1_m: 0.9539 - val_loss: 0.0717 - val_accuracy: 0.9781 - val_f1_m: 0.9494\n","Epoch 21/30\n","511/511 [==============================] - 8s 15ms/step - loss: 0.0674 - accuracy: 0.9773 - f1_m: 0.9519 - val_loss: 0.0567 - val_accuracy: 0.9790 - val_f1_m: 0.9532\n","Epoch 22/30\n","511/511 [==============================] - 9s 18ms/step - loss: 0.0548 - accuracy: 0.9821 - f1_m: 0.9600 - val_loss: 0.0477 - val_accuracy: 0.9841 - val_f1_m: 0.9690\n","Epoch 23/30\n","511/511 [==============================] - 8s 16ms/step - loss: 0.0469 - accuracy: 0.9829 - f1_m: 0.9644 - val_loss: 0.0353 - val_accuracy: 0.9880 - val_f1_m: 0.9742\n","Epoch 24/30\n","511/511 [==============================] - 8s 16ms/step - loss: 0.0457 - accuracy: 0.9851 - f1_m: 0.9692 - val_loss: 0.0354 - val_accuracy: 0.9889 - val_f1_m: 0.9739\n","Epoch 25/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.0457 - accuracy: 0.9847 - f1_m: 0.9675 - val_loss: 0.0302 - val_accuracy: 0.9906 - val_f1_m: 0.9800\n","Epoch 26/30\n","511/511 [==============================] - 7s 14ms/step - loss: 0.0483 - accuracy: 0.9838 - f1_m: 0.9668 - val_loss: 0.0750 - val_accuracy: 0.9743 - val_f1_m: 0.9461\n","Epoch 27/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.0473 - accuracy: 0.9851 - f1_m: 0.9677 - val_loss: 0.0266 - val_accuracy: 0.9936 - val_f1_m: 0.9841\n","Epoch 28/30\n","511/511 [==============================] - 7s 15ms/step - loss: 0.0423 - accuracy: 0.9857 - f1_m: 0.9693 - val_loss: 0.0235 - val_accuracy: 0.9923 - val_f1_m: 0.9852\n","Epoch 29/30\n","511/511 [==============================] - 9s 18ms/step - loss: 0.0366 - accuracy: 0.9873 - f1_m: 0.9736 - val_loss: 0.0403 - val_accuracy: 0.9820 - val_f1_m: 0.9617\n","Epoch 30/30\n","511/511 [==============================] - 8s 16ms/step - loss: 0.0338 - accuracy: 0.9888 - f1_m: 0.9760 - val_loss: 0.0205 - val_accuracy: 0.9936 - val_f1_m: 0.9838\n","Number frame of observation: 30, version: 3\n","Epoch 1/30\n","511/511 [==============================] - 19s 20ms/step - loss: 0.3410 - accuracy: 0.8660 - f1_m: 0.6569 - val_loss: 0.2800 - val_accuracy: 0.8988 - val_f1_m: 0.7636\n","Epoch 2/30\n","511/511 [==============================] - 8s 15ms/step - loss: 0.2823 - accuracy: 0.8919 - f1_m: 0.7487 - val_loss: 0.2491 - val_accuracy: 0.9061 - val_f1_m: 0.7848\n","Epoch 3/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.2611 - accuracy: 0.9011 - f1_m: 0.7725 - val_loss: 0.2345 - val_accuracy: 0.9190 - val_f1_m: 0.8159\n","Epoch 4/30\n","511/511 [==============================] - 7s 15ms/step - loss: 0.2464 - accuracy: 0.9068 - f1_m: 0.7863 - val_loss: 0.2474 - val_accuracy: 0.9053 - val_f1_m: 0.7921\n","Epoch 5/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.2311 - accuracy: 0.9140 - f1_m: 0.8088 - val_loss: 0.2050 - val_accuracy: 0.9220 - val_f1_m: 0.8186\n","Epoch 6/30\n","511/511 [==============================] - 8s 15ms/step - loss: 0.2184 - accuracy: 0.9202 - f1_m: 0.8207 - val_loss: 0.2056 - val_accuracy: 0.9263 - val_f1_m: 0.8320\n","Epoch 7/30\n","511/511 [==============================] - 8s 16ms/step - loss: 0.1993 - accuracy: 0.9266 - f1_m: 0.8362 - val_loss: 0.1794 - val_accuracy: 0.9357 - val_f1_m: 0.8539\n","Epoch 8/30\n","511/511 [==============================] - 8s 16ms/step - loss: 0.1827 - accuracy: 0.9337 - f1_m: 0.8537 - val_loss: 0.1641 - val_accuracy: 0.9404 - val_f1_m: 0.8638\n","Epoch 9/30\n","511/511 [==============================] - 8s 16ms/step - loss: 0.1653 - accuracy: 0.9428 - f1_m: 0.8744 - val_loss: 0.1373 - val_accuracy: 0.9507 - val_f1_m: 0.8908\n","Epoch 10/30\n","511/511 [==============================] - 9s 18ms/step - loss: 0.1551 - accuracy: 0.9463 - f1_m: 0.8822 - val_loss: 0.1680 - val_accuracy: 0.9357 - val_f1_m: 0.8660\n","Epoch 11/30\n","511/511 [==============================] - 7s 15ms/step - loss: 0.1400 - accuracy: 0.9513 - f1_m: 0.8956 - val_loss: 0.1573 - val_accuracy: 0.9391 - val_f1_m: 0.8713\n","Epoch 12/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.1311 - accuracy: 0.9527 - f1_m: 0.8970 - val_loss: 0.1537 - val_accuracy: 0.9486 - val_f1_m: 0.8882\n","Epoch 13/30\n","511/511 [==============================] - 8s 15ms/step - loss: 0.1251 - accuracy: 0.9538 - f1_m: 0.8957 - val_loss: 0.0865 - val_accuracy: 0.9674 - val_f1_m: 0.9292\n","Epoch 14/30\n","511/511 [==============================] - 8s 17ms/step - loss: 0.1128 - accuracy: 0.9594 - f1_m: 0.9118 - val_loss: 0.0922 - val_accuracy: 0.9691 - val_f1_m: 0.9339\n","Epoch 15/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.0998 - accuracy: 0.9647 - f1_m: 0.9258 - val_loss: 0.0748 - val_accuracy: 0.9760 - val_f1_m: 0.9502\n","Epoch 16/30\n","511/511 [==============================] - 8s 15ms/step - loss: 0.0888 - accuracy: 0.9688 - f1_m: 0.9331 - val_loss: 0.0985 - val_accuracy: 0.9691 - val_f1_m: 0.9339\n","Epoch 17/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.0842 - accuracy: 0.9703 - f1_m: 0.9355 - val_loss: 0.0635 - val_accuracy: 0.9773 - val_f1_m: 0.9565\n","Epoch 18/30\n","511/511 [==============================] - 8s 15ms/step - loss: 0.0714 - accuracy: 0.9749 - f1_m: 0.9491 - val_loss: 0.0667 - val_accuracy: 0.9760 - val_f1_m: 0.9544\n","Epoch 19/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.0764 - accuracy: 0.9714 - f1_m: 0.9381 - val_loss: 0.0601 - val_accuracy: 0.9811 - val_f1_m: 0.9607\n","Epoch 20/30\n","511/511 [==============================] - 8s 16ms/step - loss: 0.0665 - accuracy: 0.9772 - f1_m: 0.9529 - val_loss: 0.0707 - val_accuracy: 0.9756 - val_f1_m: 0.9522\n","Epoch 21/30\n","511/511 [==============================] - 8s 16ms/step - loss: 0.0606 - accuracy: 0.9798 - f1_m: 0.9563 - val_loss: 0.0574 - val_accuracy: 0.9803 - val_f1_m: 0.9628\n","Epoch 22/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.0517 - accuracy: 0.9817 - f1_m: 0.9625 - val_loss: 0.0487 - val_accuracy: 0.9867 - val_f1_m: 0.9712\n","Epoch 23/30\n","511/511 [==============================] - 8s 15ms/step - loss: 0.0547 - accuracy: 0.9797 - f1_m: 0.9538 - val_loss: 0.0376 - val_accuracy: 0.9889 - val_f1_m: 0.9807\n","Epoch 24/30\n","511/511 [==============================] - 9s 18ms/step - loss: 0.0491 - accuracy: 0.9841 - f1_m: 0.9655 - val_loss: 0.0347 - val_accuracy: 0.9889 - val_f1_m: 0.9800\n","Epoch 25/30\n","511/511 [==============================] - 8s 15ms/step - loss: 0.0530 - accuracy: 0.9835 - f1_m: 0.9639 - val_loss: 0.0447 - val_accuracy: 0.9799 - val_f1_m: 0.9602\n","Epoch 26/30\n","511/511 [==============================] - 9s 17ms/step - loss: 0.0509 - accuracy: 0.9830 - f1_m: 0.9654 - val_loss: 0.0434 - val_accuracy: 0.9859 - val_f1_m: 0.9729\n","Epoch 27/30\n","511/511 [==============================] - 8s 16ms/step - loss: 0.0417 - accuracy: 0.9860 - f1_m: 0.9714 - val_loss: 0.0590 - val_accuracy: 0.9811 - val_f1_m: 0.9618\n","Epoch 28/30\n","511/511 [==============================] - 8s 16ms/step - loss: 0.0436 - accuracy: 0.9857 - f1_m: 0.9706 - val_loss: 0.0440 - val_accuracy: 0.9850 - val_f1_m: 0.9694\n","Epoch 29/30\n","511/511 [==============================] - 9s 18ms/step - loss: 0.0371 - accuracy: 0.9882 - f1_m: 0.9763 - val_loss: 0.0424 - val_accuracy: 0.9833 - val_f1_m: 0.9679\n","Epoch 30/30\n","511/511 [==============================] - 7s 15ms/step - loss: 0.0436 - accuracy: 0.9862 - f1_m: 0.9712 - val_loss: 0.0450 - val_accuracy: 0.9846 - val_f1_m: 0.9693\n","Number frame of observation: 35, version: 1\n","Epoch 1/30\n","464/464 [==============================] - 17s 18ms/step - loss: 0.3235 - accuracy: 0.8767 - f1_m: 0.6616 - val_loss: 0.2683 - val_accuracy: 0.8976 - val_f1_m: 0.7429\n","Epoch 2/30\n","464/464 [==============================] - 9s 19ms/step - loss: 0.2562 - accuracy: 0.9087 - f1_m: 0.7673 - val_loss: 0.2370 - val_accuracy: 0.9127 - val_f1_m: 0.7804\n","Epoch 3/30\n","464/464 [==============================] - 7s 16ms/step - loss: 0.2346 - accuracy: 0.9156 - f1_m: 0.7903 - val_loss: 0.2216 - val_accuracy: 0.9212 - val_f1_m: 0.8018\n","Epoch 4/30\n","464/464 [==============================] - 8s 17ms/step - loss: 0.2202 - accuracy: 0.9216 - f1_m: 0.8025 - val_loss: 0.1979 - val_accuracy: 0.9330 - val_f1_m: 0.8377\n","Epoch 5/30\n","464/464 [==============================] - 8s 17ms/step - loss: 0.2090 - accuracy: 0.9268 - f1_m: 0.8218 - val_loss: 0.2381 - val_accuracy: 0.9108 - val_f1_m: 0.7574\n","Epoch 6/30\n","464/464 [==============================] - 8s 16ms/step - loss: 0.1976 - accuracy: 0.9321 - f1_m: 0.8333 - val_loss: 0.1754 - val_accuracy: 0.9434 - val_f1_m: 0.8647\n","Epoch 7/30\n","464/464 [==============================] - 9s 18ms/step - loss: 0.1872 - accuracy: 0.9367 - f1_m: 0.8466 - val_loss: 0.1677 - val_accuracy: 0.9471 - val_f1_m: 0.8775\n","Epoch 8/30\n","464/464 [==============================] - 7s 15ms/step - loss: 0.1688 - accuracy: 0.9440 - f1_m: 0.8628 - val_loss: 0.1464 - val_accuracy: 0.9538 - val_f1_m: 0.8918\n","Epoch 9/30\n","464/464 [==============================] - 9s 18ms/step - loss: 0.1552 - accuracy: 0.9495 - f1_m: 0.8757 - val_loss: 0.1265 - val_accuracy: 0.9604 - val_f1_m: 0.9070\n","Epoch 10/30\n","464/464 [==============================] - 7s 15ms/step - loss: 0.1513 - accuracy: 0.9505 - f1_m: 0.8818 - val_loss: 0.1242 - val_accuracy: 0.9608 - val_f1_m: 0.9071\n","Epoch 11/30\n","464/464 [==============================] - 9s 19ms/step - loss: 0.1370 - accuracy: 0.9534 - f1_m: 0.8896 - val_loss: 0.1099 - val_accuracy: 0.9632 - val_f1_m: 0.9132\n","Epoch 12/30\n","464/464 [==============================] - 7s 16ms/step - loss: 0.1319 - accuracy: 0.9568 - f1_m: 0.8944 - val_loss: 0.1190 - val_accuracy: 0.9655 - val_f1_m: 0.9200\n","Epoch 13/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.1266 - accuracy: 0.9591 - f1_m: 0.9000 - val_loss: 0.1052 - val_accuracy: 0.9679 - val_f1_m: 0.9306\n","Epoch 14/30\n","464/464 [==============================] - 8s 17ms/step - loss: 0.1096 - accuracy: 0.9647 - f1_m: 0.9146 - val_loss: 0.1665 - val_accuracy: 0.9401 - val_f1_m: 0.8736\n","Epoch 15/30\n","464/464 [==============================] - 8s 17ms/step - loss: 0.0994 - accuracy: 0.9674 - f1_m: 0.9234 - val_loss: 0.0778 - val_accuracy: 0.9764 - val_f1_m: 0.9502\n","Epoch 16/30\n","464/464 [==============================] - 9s 19ms/step - loss: 0.0953 - accuracy: 0.9681 - f1_m: 0.9249 - val_loss: 0.0763 - val_accuracy: 0.9731 - val_f1_m: 0.9406\n","Epoch 17/30\n","464/464 [==============================] - 7s 15ms/step - loss: 0.0840 - accuracy: 0.9719 - f1_m: 0.9358 - val_loss: 0.0893 - val_accuracy: 0.9689 - val_f1_m: 0.9293\n","Epoch 18/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.0774 - accuracy: 0.9730 - f1_m: 0.9363 - val_loss: 0.0652 - val_accuracy: 0.9731 - val_f1_m: 0.9436\n","Epoch 19/30\n","464/464 [==============================] - 7s 16ms/step - loss: 0.0710 - accuracy: 0.9752 - f1_m: 0.9402 - val_loss: 0.0489 - val_accuracy: 0.9821 - val_f1_m: 0.9627\n","Epoch 20/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.0718 - accuracy: 0.9748 - f1_m: 0.9389 - val_loss: 0.0433 - val_accuracy: 0.9825 - val_f1_m: 0.9632\n","Epoch 21/30\n","464/464 [==============================] - 7s 16ms/step - loss: 0.0615 - accuracy: 0.9792 - f1_m: 0.9531 - val_loss: 0.0493 - val_accuracy: 0.9825 - val_f1_m: 0.9605\n","Epoch 22/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.0571 - accuracy: 0.9829 - f1_m: 0.9618 - val_loss: 0.0503 - val_accuracy: 0.9835 - val_f1_m: 0.9666\n","Epoch 23/30\n","464/464 [==============================] - 7s 16ms/step - loss: 0.0480 - accuracy: 0.9844 - f1_m: 0.9660 - val_loss: 0.0340 - val_accuracy: 0.9887 - val_f1_m: 0.9754\n","Epoch 24/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.0545 - accuracy: 0.9830 - f1_m: 0.9609 - val_loss: 0.0204 - val_accuracy: 0.9939 - val_f1_m: 0.9876\n","Epoch 25/30\n","464/464 [==============================] - 8s 17ms/step - loss: 0.0500 - accuracy: 0.9825 - f1_m: 0.9604 - val_loss: 0.0299 - val_accuracy: 0.9906 - val_f1_m: 0.9808\n","Epoch 26/30\n","464/464 [==============================] - 8s 17ms/step - loss: 0.0391 - accuracy: 0.9873 - f1_m: 0.9726 - val_loss: 0.0222 - val_accuracy: 0.9934 - val_f1_m: 0.9870\n","Epoch 27/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.0412 - accuracy: 0.9870 - f1_m: 0.9716 - val_loss: 0.0434 - val_accuracy: 0.9877 - val_f1_m: 0.9739\n","Epoch 28/30\n","464/464 [==============================] - 8s 16ms/step - loss: 0.0385 - accuracy: 0.9869 - f1_m: 0.9697 - val_loss: 0.0203 - val_accuracy: 0.9924 - val_f1_m: 0.9844\n","Epoch 29/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.0460 - accuracy: 0.9849 - f1_m: 0.9658 - val_loss: 0.0329 - val_accuracy: 0.9891 - val_f1_m: 0.9751\n","Epoch 30/30\n","464/464 [==============================] - 7s 16ms/step - loss: 0.0237 - accuracy: 0.9923 - f1_m: 0.9826 - val_loss: 0.0095 - val_accuracy: 0.9967 - val_f1_m: 0.9929\n","Number frame of observation: 35, version: 2\n","Epoch 1/30\n","464/464 [==============================] - 17s 22ms/step - loss: 0.3175 - accuracy: 0.8789 - f1_m: 0.6666 - val_loss: 0.2610 - val_accuracy: 0.9047 - val_f1_m: 0.7238\n","Epoch 2/30\n","464/464 [==============================] - 8s 17ms/step - loss: 0.2582 - accuracy: 0.9029 - f1_m: 0.7585 - val_loss: 0.2345 - val_accuracy: 0.9184 - val_f1_m: 0.7825\n","Epoch 3/30\n","464/464 [==============================] - 8s 17ms/step - loss: 0.2278 - accuracy: 0.9153 - f1_m: 0.7863 - val_loss: 0.2201 - val_accuracy: 0.9136 - val_f1_m: 0.7841\n","Epoch 4/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.2052 - accuracy: 0.9262 - f1_m: 0.8176 - val_loss: 0.2115 - val_accuracy: 0.9245 - val_f1_m: 0.8146\n","Epoch 5/30\n","464/464 [==============================] - 7s 16ms/step - loss: 0.1910 - accuracy: 0.9338 - f1_m: 0.8360 - val_loss: 0.1861 - val_accuracy: 0.9349 - val_f1_m: 0.8254\n","Epoch 6/30\n","464/464 [==============================] - 9s 19ms/step - loss: 0.1736 - accuracy: 0.9415 - f1_m: 0.8574 - val_loss: 0.1686 - val_accuracy: 0.9415 - val_f1_m: 0.8503\n","Epoch 7/30\n","464/464 [==============================] - 7s 16ms/step - loss: 0.1541 - accuracy: 0.9490 - f1_m: 0.8781 - val_loss: 0.1419 - val_accuracy: 0.9538 - val_f1_m: 0.8777\n","Epoch 8/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.1349 - accuracy: 0.9549 - f1_m: 0.8933 - val_loss: 0.1121 - val_accuracy: 0.9655 - val_f1_m: 0.9123\n","Epoch 9/30\n","464/464 [==============================] - 7s 15ms/step - loss: 0.1216 - accuracy: 0.9588 - f1_m: 0.9018 - val_loss: 0.1272 - val_accuracy: 0.9580 - val_f1_m: 0.8842\n","Epoch 10/30\n","464/464 [==============================] - 9s 19ms/step - loss: 0.1154 - accuracy: 0.9619 - f1_m: 0.9108 - val_loss: 0.1067 - val_accuracy: 0.9627 - val_f1_m: 0.9042\n","Epoch 11/30\n","464/464 [==============================] - 8s 16ms/step - loss: 0.1011 - accuracy: 0.9668 - f1_m: 0.9223 - val_loss: 0.1119 - val_accuracy: 0.9632 - val_f1_m: 0.9003\n","Epoch 12/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.0872 - accuracy: 0.9699 - f1_m: 0.9292 - val_loss: 0.0636 - val_accuracy: 0.9783 - val_f1_m: 0.9386\n","Epoch 13/30\n","464/464 [==============================] - 8s 17ms/step - loss: 0.0710 - accuracy: 0.9759 - f1_m: 0.9417 - val_loss: 0.0633 - val_accuracy: 0.9802 - val_f1_m: 0.9440\n","Epoch 14/30\n","464/464 [==============================] - 8s 17ms/step - loss: 0.0714 - accuracy: 0.9761 - f1_m: 0.9442 - val_loss: 0.0741 - val_accuracy: 0.9736 - val_f1_m: 0.9333\n","Epoch 15/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.0725 - accuracy: 0.9746 - f1_m: 0.9429 - val_loss: 0.0506 - val_accuracy: 0.9821 - val_f1_m: 0.9562\n","Epoch 16/30\n","464/464 [==============================] - 7s 16ms/step - loss: 0.0521 - accuracy: 0.9829 - f1_m: 0.9595 - val_loss: 0.0415 - val_accuracy: 0.9877 - val_f1_m: 0.9690\n","Epoch 17/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.0690 - accuracy: 0.9771 - f1_m: 0.9449 - val_loss: 0.0437 - val_accuracy: 0.9873 - val_f1_m: 0.9665\n","Epoch 18/30\n","464/464 [==============================] - 7s 16ms/step - loss: 0.0527 - accuracy: 0.9823 - f1_m: 0.9602 - val_loss: 0.0580 - val_accuracy: 0.9830 - val_f1_m: 0.9596\n","Epoch 19/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.0406 - accuracy: 0.9874 - f1_m: 0.9698 - val_loss: 0.0285 - val_accuracy: 0.9891 - val_f1_m: 0.9758\n","Epoch 20/30\n","464/464 [==============================] - 7s 15ms/step - loss: 0.0412 - accuracy: 0.9865 - f1_m: 0.9707 - val_loss: 0.0564 - val_accuracy: 0.9778 - val_f1_m: 0.9468\n","Epoch 21/30\n","464/464 [==============================] - 9s 18ms/step - loss: 0.0376 - accuracy: 0.9877 - f1_m: 0.9724 - val_loss: 0.0898 - val_accuracy: 0.9726 - val_f1_m: 0.9421\n","Epoch 22/30\n","464/464 [==============================] - 8s 16ms/step - loss: 0.0373 - accuracy: 0.9871 - f1_m: 0.9704 - val_loss: 0.0284 - val_accuracy: 0.9901 - val_f1_m: 0.9759\n","Epoch 23/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.0262 - accuracy: 0.9913 - f1_m: 0.9799 - val_loss: 0.0290 - val_accuracy: 0.9891 - val_f1_m: 0.9722\n","Epoch 24/30\n","464/464 [==============================] - 8s 17ms/step - loss: 0.0390 - accuracy: 0.9876 - f1_m: 0.9727 - val_loss: 0.0223 - val_accuracy: 0.9943 - val_f1_m: 0.9876\n","Epoch 25/30\n","464/464 [==============================] - 8s 17ms/step - loss: 0.0317 - accuracy: 0.9894 - f1_m: 0.9766 - val_loss: 0.0140 - val_accuracy: 0.9943 - val_f1_m: 0.9876\n","Epoch 26/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.0212 - accuracy: 0.9925 - f1_m: 0.9833 - val_loss: 0.0489 - val_accuracy: 0.9835 - val_f1_m: 0.9649\n","Epoch 27/30\n","464/464 [==============================] - 8s 17ms/step - loss: 0.0322 - accuracy: 0.9896 - f1_m: 0.9766 - val_loss: 0.0669 - val_accuracy: 0.9797 - val_f1_m: 0.9446\n","Epoch 28/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.0302 - accuracy: 0.9899 - f1_m: 0.9782 - val_loss: 0.0303 - val_accuracy: 0.9910 - val_f1_m: 0.9810\n","Epoch 29/30\n","464/464 [==============================] - 7s 16ms/step - loss: 0.0287 - accuracy: 0.9899 - f1_m: 0.9765 - val_loss: 0.0223 - val_accuracy: 0.9906 - val_f1_m: 0.9798\n","Epoch 30/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.0221 - accuracy: 0.9928 - f1_m: 0.9835 - val_loss: 0.0210 - val_accuracy: 0.9929 - val_f1_m: 0.9843\n","Number frame of observation: 35, version: 3\n","Epoch 1/30\n","464/464 [==============================] - 18s 19ms/step - loss: 0.3258 - accuracy: 0.8756 - f1_m: 0.6618 - val_loss: 0.2903 - val_accuracy: 0.8900 - val_f1_m: 0.7127\n","Epoch 2/30\n","464/464 [==============================] - 9s 18ms/step - loss: 0.2701 - accuracy: 0.8980 - f1_m: 0.7391 - val_loss: 0.2591 - val_accuracy: 0.9118 - val_f1_m: 0.7644\n","Epoch 3/30\n","464/464 [==============================] - 8s 17ms/step - loss: 0.2408 - accuracy: 0.9108 - f1_m: 0.7709 - val_loss: 0.2221 - val_accuracy: 0.9179 - val_f1_m: 0.7907\n","Epoch 4/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.2168 - accuracy: 0.9208 - f1_m: 0.8053 - val_loss: 0.1863 - val_accuracy: 0.9358 - val_f1_m: 0.8357\n","Epoch 5/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.1993 - accuracy: 0.9291 - f1_m: 0.8259 - val_loss: 0.1884 - val_accuracy: 0.9363 - val_f1_m: 0.8428\n","Epoch 6/30\n","464/464 [==============================] - 7s 16ms/step - loss: 0.1847 - accuracy: 0.9352 - f1_m: 0.8409 - val_loss: 0.1709 - val_accuracy: 0.9387 - val_f1_m: 0.8424\n","Epoch 7/30\n","464/464 [==============================] - 9s 19ms/step - loss: 0.1685 - accuracy: 0.9423 - f1_m: 0.8602 - val_loss: 0.1710 - val_accuracy: 0.9396 - val_f1_m: 0.8549\n","Epoch 8/30\n","464/464 [==============================] - 7s 16ms/step - loss: 0.1562 - accuracy: 0.9473 - f1_m: 0.8774 - val_loss: 0.1273 - val_accuracy: 0.9613 - val_f1_m: 0.9035\n","Epoch 9/30\n","464/464 [==============================] - 9s 19ms/step - loss: 0.1359 - accuracy: 0.9556 - f1_m: 0.8895 - val_loss: 0.1329 - val_accuracy: 0.9589 - val_f1_m: 0.8957\n","Epoch 10/30\n","464/464 [==============================] - 7s 16ms/step - loss: 0.1309 - accuracy: 0.9569 - f1_m: 0.8992 - val_loss: 0.1237 - val_accuracy: 0.9632 - val_f1_m: 0.9075\n","Epoch 11/30\n","464/464 [==============================] - 9s 18ms/step - loss: 0.1264 - accuracy: 0.9584 - f1_m: 0.9029 - val_loss: 0.1081 - val_accuracy: 0.9637 - val_f1_m: 0.9079\n","Epoch 12/30\n","464/464 [==============================] - 8s 16ms/step - loss: 0.1071 - accuracy: 0.9640 - f1_m: 0.9133 - val_loss: 0.0906 - val_accuracy: 0.9674 - val_f1_m: 0.9155\n","Epoch 13/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.1074 - accuracy: 0.9639 - f1_m: 0.9161 - val_loss: 0.1395 - val_accuracy: 0.9533 - val_f1_m: 0.8850\n","Epoch 14/30\n","464/464 [==============================] - 8s 17ms/step - loss: 0.0939 - accuracy: 0.9695 - f1_m: 0.9238 - val_loss: 0.0891 - val_accuracy: 0.9703 - val_f1_m: 0.9245\n","Epoch 15/30\n","464/464 [==============================] - 8s 17ms/step - loss: 0.0953 - accuracy: 0.9676 - f1_m: 0.9219 - val_loss: 0.0660 - val_accuracy: 0.9740 - val_f1_m: 0.9312\n","Epoch 16/30\n","464/464 [==============================] - 9s 19ms/step - loss: 0.0819 - accuracy: 0.9715 - f1_m: 0.9347 - val_loss: 0.0697 - val_accuracy: 0.9722 - val_f1_m: 0.9365\n","Epoch 17/30\n","464/464 [==============================] - 7s 16ms/step - loss: 0.0780 - accuracy: 0.9743 - f1_m: 0.9390 - val_loss: 0.0449 - val_accuracy: 0.9835 - val_f1_m: 0.9628\n","Epoch 18/30\n","464/464 [==============================] - 9s 19ms/step - loss: 0.0627 - accuracy: 0.9782 - f1_m: 0.9495 - val_loss: 0.0480 - val_accuracy: 0.9792 - val_f1_m: 0.9527\n","Epoch 19/30\n","464/464 [==============================] - 8s 17ms/step - loss: 0.0572 - accuracy: 0.9792 - f1_m: 0.9520 - val_loss: 0.0626 - val_accuracy: 0.9740 - val_f1_m: 0.9406\n","Epoch 20/30\n","464/464 [==============================] - 9s 19ms/step - loss: 0.0557 - accuracy: 0.9806 - f1_m: 0.9538 - val_loss: 0.0408 - val_accuracy: 0.9849 - val_f1_m: 0.9665\n","Epoch 21/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.0581 - accuracy: 0.9798 - f1_m: 0.9536 - val_loss: 0.0409 - val_accuracy: 0.9896 - val_f1_m: 0.9758\n","Epoch 22/30\n","464/464 [==============================] - 8s 18ms/step - loss: 0.0478 - accuracy: 0.9841 - f1_m: 0.9630 - val_loss: 0.0296 - val_accuracy: 0.9896 - val_f1_m: 0.9758\n","Epoch 23/30\n","464/464 [==============================] - 9s 19ms/step - loss: 0.0398 - accuracy: 0.9866 - f1_m: 0.9697 - val_loss: 0.0271 - val_accuracy: 0.9915 - val_f1_m: 0.9800\n","Epoch 24/30\n","464/464 [==============================] - 7s 16ms/step - loss: 0.0423 - accuracy: 0.9854 - f1_m: 0.9663 - val_loss: 0.0297 - val_accuracy: 0.9896 - val_f1_m: 0.9739\n","Epoch 25/30\n","464/464 [==============================] - 9s 20ms/step - loss: 0.0413 - accuracy: 0.9860 - f1_m: 0.9679 - val_loss: 0.0163 - val_accuracy: 0.9962 - val_f1_m: 0.9908\n","Epoch 26/30\n","464/464 [==============================] - 8s 17ms/step - loss: 0.0303 - accuracy: 0.9909 - f1_m: 0.9803 - val_loss: 0.0323 - val_accuracy: 0.9901 - val_f1_m: 0.9741\n","Epoch 27/30\n","464/464 [==============================] - 9s 20ms/step - loss: 0.0350 - accuracy: 0.9887 - f1_m: 0.9743 - val_loss: 0.0286 - val_accuracy: 0.9910 - val_f1_m: 0.9787\n","Epoch 28/30\n","464/464 [==============================] - 8s 17ms/step - loss: 0.0345 - accuracy: 0.9885 - f1_m: 0.9735 - val_loss: 0.0144 - val_accuracy: 0.9967 - val_f1_m: 0.9888\n","Epoch 29/30\n","464/464 [==============================] - 9s 19ms/step - loss: 0.0261 - accuracy: 0.9914 - f1_m: 0.9802 - val_loss: 0.0247 - val_accuracy: 0.9906 - val_f1_m: 0.9786\n","Epoch 30/30\n","464/464 [==============================] - 9s 19ms/step - loss: 0.0308 - accuracy: 0.9901 - f1_m: 0.9779 - val_loss: 0.0142 - val_accuracy: 0.9953 - val_f1_m: 0.9901\n","Number frame of observation: 40, version: 1\n","Epoch 1/30\n","420/420 [==============================] - 17s 23ms/step - loss: 0.3071 - accuracy: 0.8845 - f1_m: 0.6620 - val_loss: 0.4977 - val_accuracy: 0.8494 - val_f1_m: 0.6758\n","Epoch 2/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.2476 - accuracy: 0.9082 - f1_m: 0.7466 - val_loss: 0.2384 - val_accuracy: 0.9130 - val_f1_m: 0.7779\n","Epoch 3/30\n","420/420 [==============================] - 8s 20ms/step - loss: 0.2148 - accuracy: 0.9236 - f1_m: 0.7946 - val_loss: 0.1981 - val_accuracy: 0.9250 - val_f1_m: 0.7916\n","Epoch 4/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.1903 - accuracy: 0.9330 - f1_m: 0.8170 - val_loss: 0.1731 - val_accuracy: 0.9406 - val_f1_m: 0.8453\n","Epoch 5/30\n","420/420 [==============================] - 8s 19ms/step - loss: 0.1767 - accuracy: 0.9403 - f1_m: 0.8462 - val_loss: 0.1498 - val_accuracy: 0.9474 - val_f1_m: 0.8470\n","Epoch 6/30\n","420/420 [==============================] - 7s 16ms/step - loss: 0.1532 - accuracy: 0.9492 - f1_m: 0.8686 - val_loss: 0.1222 - val_accuracy: 0.9515 - val_f1_m: 0.8713\n","Epoch 7/30\n","420/420 [==============================] - 9s 20ms/step - loss: 0.1355 - accuracy: 0.9535 - f1_m: 0.8792 - val_loss: 0.1079 - val_accuracy: 0.9646 - val_f1_m: 0.8986\n","Epoch 8/30\n","420/420 [==============================] - 7s 16ms/step - loss: 0.1322 - accuracy: 0.9564 - f1_m: 0.8862 - val_loss: 0.1325 - val_accuracy: 0.9552 - val_f1_m: 0.8758\n","Epoch 9/30\n","420/420 [==============================] - 8s 19ms/step - loss: 0.1075 - accuracy: 0.9637 - f1_m: 0.9098 - val_loss: 0.0675 - val_accuracy: 0.9786 - val_f1_m: 0.9446\n","Epoch 10/30\n","420/420 [==============================] - 7s 16ms/step - loss: 0.0920 - accuracy: 0.9685 - f1_m: 0.9200 - val_loss: 0.0671 - val_accuracy: 0.9766 - val_f1_m: 0.9419\n","Epoch 11/30\n","420/420 [==============================] - 8s 19ms/step - loss: 0.0836 - accuracy: 0.9717 - f1_m: 0.9278 - val_loss: 0.0555 - val_accuracy: 0.9823 - val_f1_m: 0.9536\n","Epoch 12/30\n","420/420 [==============================] - 7s 16ms/step - loss: 0.0786 - accuracy: 0.9727 - f1_m: 0.9307 - val_loss: 0.0687 - val_accuracy: 0.9792 - val_f1_m: 0.9492\n","Epoch 13/30\n","420/420 [==============================] - 8s 20ms/step - loss: 0.0690 - accuracy: 0.9760 - f1_m: 0.9403 - val_loss: 0.0684 - val_accuracy: 0.9786 - val_f1_m: 0.9517\n","Epoch 14/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.0638 - accuracy: 0.9773 - f1_m: 0.9435 - val_loss: 0.0513 - val_accuracy: 0.9828 - val_f1_m: 0.9597\n","Epoch 15/30\n","420/420 [==============================] - 8s 19ms/step - loss: 0.0643 - accuracy: 0.9781 - f1_m: 0.9463 - val_loss: 0.0896 - val_accuracy: 0.9703 - val_f1_m: 0.9150\n","Epoch 16/30\n","420/420 [==============================] - 7s 16ms/step - loss: 0.0623 - accuracy: 0.9792 - f1_m: 0.9491 - val_loss: 0.0500 - val_accuracy: 0.9838 - val_f1_m: 0.9589\n","Epoch 17/30\n","420/420 [==============================] - 8s 19ms/step - loss: 0.0502 - accuracy: 0.9842 - f1_m: 0.9602 - val_loss: 0.0329 - val_accuracy: 0.9875 - val_f1_m: 0.9702\n","Epoch 18/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.0395 - accuracy: 0.9870 - f1_m: 0.9659 - val_loss: 0.0617 - val_accuracy: 0.9776 - val_f1_m: 0.9513\n","Epoch 19/30\n","420/420 [==============================] - 8s 19ms/step - loss: 0.0439 - accuracy: 0.9853 - f1_m: 0.9635 - val_loss: 0.0355 - val_accuracy: 0.9891 - val_f1_m: 0.9767\n","Epoch 20/30\n","420/420 [==============================] - 7s 18ms/step - loss: 0.0394 - accuracy: 0.9864 - f1_m: 0.9677 - val_loss: 0.0265 - val_accuracy: 0.9917 - val_f1_m: 0.9806\n","Epoch 21/30\n","420/420 [==============================] - 8s 18ms/step - loss: 0.0469 - accuracy: 0.9852 - f1_m: 0.9646 - val_loss: 0.0402 - val_accuracy: 0.9838 - val_f1_m: 0.9604\n","Epoch 22/30\n","420/420 [==============================] - 8s 18ms/step - loss: 0.0343 - accuracy: 0.9894 - f1_m: 0.9738 - val_loss: 0.0576 - val_accuracy: 0.9812 - val_f1_m: 0.9563\n","Epoch 23/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.0341 - accuracy: 0.9894 - f1_m: 0.9726 - val_loss: 0.0324 - val_accuracy: 0.9901 - val_f1_m: 0.9769\n","Epoch 24/30\n","420/420 [==============================] - 8s 18ms/step - loss: 0.0228 - accuracy: 0.9924 - f1_m: 0.9822 - val_loss: 0.0391 - val_accuracy: 0.9891 - val_f1_m: 0.9741\n","Epoch 25/30\n","420/420 [==============================] - 8s 18ms/step - loss: 0.0228 - accuracy: 0.9926 - f1_m: 0.9822 - val_loss: 0.0091 - val_accuracy: 0.9969 - val_f1_m: 0.9918\n","Epoch 26/30\n","420/420 [==============================] - 8s 18ms/step - loss: 0.0445 - accuracy: 0.9837 - f1_m: 0.9619 - val_loss: 0.0428 - val_accuracy: 0.9865 - val_f1_m: 0.9677\n","Epoch 27/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.0229 - accuracy: 0.9925 - f1_m: 0.9785 - val_loss: 0.0185 - val_accuracy: 0.9932 - val_f1_m: 0.9826\n","Epoch 28/30\n","420/420 [==============================] - 8s 18ms/step - loss: 0.0230 - accuracy: 0.9928 - f1_m: 0.9830 - val_loss: 0.0134 - val_accuracy: 0.9964 - val_f1_m: 0.9918\n","Epoch 29/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.0268 - accuracy: 0.9914 - f1_m: 0.9783 - val_loss: 0.0056 - val_accuracy: 0.9974 - val_f1_m: 0.9936\n","Epoch 30/30\n","420/420 [==============================] - 8s 20ms/step - loss: 0.0310 - accuracy: 0.9902 - f1_m: 0.9763 - val_loss: 0.0094 - val_accuracy: 0.9964 - val_f1_m: 0.9912\n","Number frame of observation: 40, version: 2\n","Epoch 1/30\n","420/420 [==============================] - 19s 23ms/step - loss: 0.3057 - accuracy: 0.8827 - f1_m: 0.6512 - val_loss: 0.3468 - val_accuracy: 0.8812 - val_f1_m: 0.7179\n","Epoch 2/30\n","420/420 [==============================] - 7s 16ms/step - loss: 0.2456 - accuracy: 0.9111 - f1_m: 0.7522 - val_loss: 0.2570 - val_accuracy: 0.9083 - val_f1_m: 0.7347\n","Epoch 3/30\n","420/420 [==============================] - 8s 19ms/step - loss: 0.2201 - accuracy: 0.9237 - f1_m: 0.7935 - val_loss: 0.2017 - val_accuracy: 0.9302 - val_f1_m: 0.7927\n","Epoch 4/30\n","420/420 [==============================] - 7s 16ms/step - loss: 0.1925 - accuracy: 0.9334 - f1_m: 0.8247 - val_loss: 0.1746 - val_accuracy: 0.9411 - val_f1_m: 0.8342\n","Epoch 5/30\n","420/420 [==============================] - 8s 19ms/step - loss: 0.1712 - accuracy: 0.9433 - f1_m: 0.8519 - val_loss: 0.1732 - val_accuracy: 0.9401 - val_f1_m: 0.8299\n","Epoch 6/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.1558 - accuracy: 0.9494 - f1_m: 0.8655 - val_loss: 0.1379 - val_accuracy: 0.9573 - val_f1_m: 0.8879\n","Epoch 7/30\n","420/420 [==============================] - 9s 20ms/step - loss: 0.1328 - accuracy: 0.9564 - f1_m: 0.8881 - val_loss: 0.1456 - val_accuracy: 0.9526 - val_f1_m: 0.8692\n","Epoch 8/30\n","420/420 [==============================] - 7s 16ms/step - loss: 0.1171 - accuracy: 0.9620 - f1_m: 0.9047 - val_loss: 0.1203 - val_accuracy: 0.9594 - val_f1_m: 0.8987\n","Epoch 9/30\n","420/420 [==============================] - 8s 19ms/step - loss: 0.1069 - accuracy: 0.9655 - f1_m: 0.9133 - val_loss: 0.1207 - val_accuracy: 0.9573 - val_f1_m: 0.8872\n","Epoch 10/30\n","420/420 [==============================] - 7s 16ms/step - loss: 0.0963 - accuracy: 0.9699 - f1_m: 0.9241 - val_loss: 0.1518 - val_accuracy: 0.9385 - val_f1_m: 0.8623\n","Epoch 11/30\n","420/420 [==============================] - 8s 19ms/step - loss: 0.0828 - accuracy: 0.9728 - f1_m: 0.9310 - val_loss: 0.1060 - val_accuracy: 0.9625 - val_f1_m: 0.9007\n","Epoch 12/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.0828 - accuracy: 0.9717 - f1_m: 0.9319 - val_loss: 0.1188 - val_accuracy: 0.9672 - val_f1_m: 0.9147\n","Epoch 13/30\n","420/420 [==============================] - 8s 19ms/step - loss: 0.0736 - accuracy: 0.9745 - f1_m: 0.9313 - val_loss: 0.0812 - val_accuracy: 0.9734 - val_f1_m: 0.9292\n","Epoch 14/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.0671 - accuracy: 0.9778 - f1_m: 0.9453 - val_loss: 0.0445 - val_accuracy: 0.9833 - val_f1_m: 0.9583\n","Epoch 15/30\n","420/420 [==============================] - 8s 20ms/step - loss: 0.0517 - accuracy: 0.9807 - f1_m: 0.9541 - val_loss: 0.0473 - val_accuracy: 0.9849 - val_f1_m: 0.9621\n","Epoch 16/30\n","420/420 [==============================] - 7s 16ms/step - loss: 0.0527 - accuracy: 0.9814 - f1_m: 0.9557 - val_loss: 0.1069 - val_accuracy: 0.9682 - val_f1_m: 0.9155\n","Epoch 17/30\n","420/420 [==============================] - 8s 19ms/step - loss: 0.0577 - accuracy: 0.9795 - f1_m: 0.9486 - val_loss: 0.0364 - val_accuracy: 0.9875 - val_f1_m: 0.9693\n","Epoch 18/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.0419 - accuracy: 0.9856 - f1_m: 0.9663 - val_loss: 0.0394 - val_accuracy: 0.9875 - val_f1_m: 0.9679\n","Epoch 19/30\n","420/420 [==============================] - 8s 19ms/step - loss: 0.0509 - accuracy: 0.9812 - f1_m: 0.9525 - val_loss: 0.0210 - val_accuracy: 0.9932 - val_f1_m: 0.9819\n","Epoch 20/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.0308 - accuracy: 0.9900 - f1_m: 0.9745 - val_loss: 0.0340 - val_accuracy: 0.9891 - val_f1_m: 0.9718\n","Epoch 21/30\n","420/420 [==============================] - 8s 18ms/step - loss: 0.0342 - accuracy: 0.9892 - f1_m: 0.9722 - val_loss: 0.0763 - val_accuracy: 0.9734 - val_f1_m: 0.9318\n","Epoch 22/30\n","420/420 [==============================] - 8s 19ms/step - loss: 0.0305 - accuracy: 0.9895 - f1_m: 0.9740 - val_loss: 0.0153 - val_accuracy: 0.9943 - val_f1_m: 0.9838\n","Epoch 23/30\n","420/420 [==============================] - 7s 18ms/step - loss: 0.0318 - accuracy: 0.9892 - f1_m: 0.9737 - val_loss: 0.0463 - val_accuracy: 0.9865 - val_f1_m: 0.9654\n","Epoch 24/30\n","420/420 [==============================] - 8s 18ms/step - loss: 0.0276 - accuracy: 0.9911 - f1_m: 0.9783 - val_loss: 0.0147 - val_accuracy: 0.9958 - val_f1_m: 0.9897\n","Epoch 25/30\n","420/420 [==============================] - 8s 18ms/step - loss: 0.0208 - accuracy: 0.9926 - f1_m: 0.9805 - val_loss: 0.0180 - val_accuracy: 0.9943 - val_f1_m: 0.9868\n","Epoch 26/30\n","420/420 [==============================] - 8s 19ms/step - loss: 0.0229 - accuracy: 0.9923 - f1_m: 0.9808 - val_loss: 0.0430 - val_accuracy: 0.9838 - val_f1_m: 0.9597\n","Epoch 27/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.0253 - accuracy: 0.9918 - f1_m: 0.9805 - val_loss: 0.0201 - val_accuracy: 0.9932 - val_f1_m: 0.9812\n","Epoch 28/30\n","420/420 [==============================] - 8s 19ms/step - loss: 0.0256 - accuracy: 0.9920 - f1_m: 0.9782 - val_loss: 0.0300 - val_accuracy: 0.9922 - val_f1_m: 0.9788\n","Epoch 29/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.0215 - accuracy: 0.9934 - f1_m: 0.9832 - val_loss: 0.0296 - val_accuracy: 0.9911 - val_f1_m: 0.9784\n","Epoch 30/30\n","420/420 [==============================] - 8s 20ms/step - loss: 0.0151 - accuracy: 0.9956 - f1_m: 0.9904 - val_loss: 0.0634 - val_accuracy: 0.9838 - val_f1_m: 0.9550\n","Number frame of observation: 40, version: 3\n","Epoch 1/30\n","420/420 [==============================] - 17s 20ms/step - loss: 0.3086 - accuracy: 0.8832 - f1_m: 0.6441 - val_loss: 0.2580 - val_accuracy: 0.9067 - val_f1_m: 0.7416\n","Epoch 2/30\n","420/420 [==============================] - 8s 19ms/step - loss: 0.2355 - accuracy: 0.9151 - f1_m: 0.7627 - val_loss: 0.2235 - val_accuracy: 0.9192 - val_f1_m: 0.7676\n","Epoch 3/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.2105 - accuracy: 0.9263 - f1_m: 0.7998 - val_loss: 0.1803 - val_accuracy: 0.9437 - val_f1_m: 0.8526\n","Epoch 4/30\n","420/420 [==============================] - 8s 18ms/step - loss: 0.1902 - accuracy: 0.9340 - f1_m: 0.8201 - val_loss: 0.1612 - val_accuracy: 0.9442 - val_f1_m: 0.8527\n","Epoch 5/30\n","420/420 [==============================] - 8s 18ms/step - loss: 0.1775 - accuracy: 0.9395 - f1_m: 0.8348 - val_loss: 0.1428 - val_accuracy: 0.9510 - val_f1_m: 0.8772\n","Epoch 6/30\n","420/420 [==============================] - 8s 18ms/step - loss: 0.1591 - accuracy: 0.9488 - f1_m: 0.8654 - val_loss: 0.1224 - val_accuracy: 0.9640 - val_f1_m: 0.9059\n","Epoch 7/30\n","420/420 [==============================] - 8s 19ms/step - loss: 0.1513 - accuracy: 0.9492 - f1_m: 0.8632 - val_loss: 0.1060 - val_accuracy: 0.9656 - val_f1_m: 0.9056\n","Epoch 8/30\n","420/420 [==============================] - 8s 18ms/step - loss: 0.1389 - accuracy: 0.9547 - f1_m: 0.8847 - val_loss: 0.1256 - val_accuracy: 0.9557 - val_f1_m: 0.8858\n","Epoch 9/30\n","420/420 [==============================] - 8s 19ms/step - loss: 0.1343 - accuracy: 0.9543 - f1_m: 0.8808 - val_loss: 0.1280 - val_accuracy: 0.9541 - val_f1_m: 0.8756\n","Epoch 10/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.1168 - accuracy: 0.9605 - f1_m: 0.8945 - val_loss: 0.1043 - val_accuracy: 0.9661 - val_f1_m: 0.9127\n","Epoch 11/30\n","420/420 [==============================] - 8s 20ms/step - loss: 0.1183 - accuracy: 0.9607 - f1_m: 0.8977 - val_loss: 0.0817 - val_accuracy: 0.9766 - val_f1_m: 0.9418\n","Epoch 12/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.0865 - accuracy: 0.9698 - f1_m: 0.9241 - val_loss: 0.1006 - val_accuracy: 0.9630 - val_f1_m: 0.9164\n","Epoch 13/30\n","420/420 [==============================] - 8s 20ms/step - loss: 0.0895 - accuracy: 0.9687 - f1_m: 0.9218 - val_loss: 0.0632 - val_accuracy: 0.9771 - val_f1_m: 0.9447\n","Epoch 14/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.0756 - accuracy: 0.9739 - f1_m: 0.9346 - val_loss: 0.0576 - val_accuracy: 0.9771 - val_f1_m: 0.9433\n","Epoch 15/30\n","420/420 [==============================] - 8s 20ms/step - loss: 0.0667 - accuracy: 0.9763 - f1_m: 0.9411 - val_loss: 0.0462 - val_accuracy: 0.9823 - val_f1_m: 0.9575\n","Epoch 16/30\n","420/420 [==============================] - 7s 16ms/step - loss: 0.0655 - accuracy: 0.9774 - f1_m: 0.9443 - val_loss: 0.0403 - val_accuracy: 0.9870 - val_f1_m: 0.9669\n","Epoch 17/30\n","420/420 [==============================] - 8s 20ms/step - loss: 0.0524 - accuracy: 0.9817 - f1_m: 0.9536 - val_loss: 0.0205 - val_accuracy: 0.9922 - val_f1_m: 0.9820\n","Epoch 18/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.0686 - accuracy: 0.9782 - f1_m: 0.9491 - val_loss: 0.0602 - val_accuracy: 0.9771 - val_f1_m: 0.9469\n","Epoch 19/30\n","420/420 [==============================] - 8s 20ms/step - loss: 0.0465 - accuracy: 0.9840 - f1_m: 0.9607 - val_loss: 0.0290 - val_accuracy: 0.9922 - val_f1_m: 0.9820\n","Epoch 20/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.0444 - accuracy: 0.9856 - f1_m: 0.9646 - val_loss: 0.0216 - val_accuracy: 0.9922 - val_f1_m: 0.9835\n","Epoch 21/30\n","420/420 [==============================] - 8s 20ms/step - loss: 0.0350 - accuracy: 0.9879 - f1_m: 0.9686 - val_loss: 0.0356 - val_accuracy: 0.9859 - val_f1_m: 0.9649\n","Epoch 22/30\n","420/420 [==============================] - 7s 16ms/step - loss: 0.0314 - accuracy: 0.9900 - f1_m: 0.9762 - val_loss: 0.0090 - val_accuracy: 0.9969 - val_f1_m: 0.9930\n","Epoch 23/30\n","420/420 [==============================] - 8s 20ms/step - loss: 0.0347 - accuracy: 0.9887 - f1_m: 0.9710 - val_loss: 0.0426 - val_accuracy: 0.9849 - val_f1_m: 0.9649\n","Epoch 24/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.0220 - accuracy: 0.9933 - f1_m: 0.9806 - val_loss: 0.0140 - val_accuracy: 0.9948 - val_f1_m: 0.9870\n","Epoch 25/30\n","420/420 [==============================] - 8s 19ms/step - loss: 0.0262 - accuracy: 0.9910 - f1_m: 0.9784 - val_loss: 0.0156 - val_accuracy: 0.9958 - val_f1_m: 0.9895\n","Epoch 26/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.0291 - accuracy: 0.9907 - f1_m: 0.9780 - val_loss: 0.0075 - val_accuracy: 0.9969 - val_f1_m: 0.9941\n","Epoch 27/30\n","420/420 [==============================] - 9s 21ms/step - loss: 0.0312 - accuracy: 0.9900 - f1_m: 0.9746 - val_loss: 0.0440 - val_accuracy: 0.9854 - val_f1_m: 0.9679\n","Epoch 28/30\n","420/420 [==============================] - 7s 17ms/step - loss: 0.0245 - accuracy: 0.9917 - f1_m: 0.9785 - val_loss: 0.0161 - val_accuracy: 0.9958 - val_f1_m: 0.9913\n","Epoch 29/30\n","420/420 [==============================] - 9s 20ms/step - loss: 0.0311 - accuracy: 0.9903 - f1_m: 0.9782 - val_loss: 0.0233 - val_accuracy: 0.9922 - val_f1_m: 0.9812\n","Epoch 30/30\n","420/420 [==============================] - 8s 18ms/step - loss: 0.0307 - accuracy: 0.9907 - f1_m: 0.9783 - val_loss: 0.0107 - val_accuracy: 0.9984 - val_f1_m: 0.9966\n"]}]},{"cell_type":"markdown","metadata":{"id":"e6lVG9OhfWXn"},"source":["## **Kết quả test**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JusCWoFzDtYJ"},"outputs":[],"source":["# Compile the model with the confusion matrix metric\n","def confusion_matrix_metric(y_true, y_pred):\n","  cm = confusion_matrix(y_true, y_pred)\n","  tn, fp, fn, tp = cm.ravel() #Hàm ravel() được sử dụng để làm phẳng ma trận nhầm lẫn thành một mảng 1 chiều, sau đó được giải nén thành bốn biến.\n","  precision = tp / (tp + fp)\n","  recall = tp / (tp + fn)\n","  f1_score = 2 * precision * recall / (precision + recall) #harmonic mean of precision and recall\n","  return f1_score\n","\n","def test(timestep, version):\n","  dependencies = {\n","    'f1_m': f1_m\n","  }\n","  modelLSTM = tf.keras.models.load_model(f'/content/drive/MyDrive/PBL5/_Top-down-Framework/modelLSTM/model_lstm_{timestep}frames_v{version}.h5', dependencies)\n","\n","  with open(f'_Top-down-Framework/features/test/features_{timestep}frames_test_v{version}', \"rb\") as f:\n","      X_test = np.load(f)\n","      f.close()\n","  with open(f'_Top-down-Framework/features/test/labels_{timestep}frames_test_v{version}', \"rb\") as f:\n","      y_test = np.load(f)\n","      f.close()\n","  scores = modelLSTM.evaluate(X_test, y_test, verbose=1)\n","  print('Test loss:', scores[0])\n","  print('Test accuracy:', scores[1])\n","\n","  modelLSTM.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', confusion_matrix_metric])\n","\n","  # Make predictions on test data\n","  y_pred = modelLSTM.predict(X_test)\n","\n","  # RMSE\n","  rmse_result = rmse(y_test, y_pred)\n","  print('rmse_Result: ', rmse_result)\n","\n","  # Làm tròn 0, 1\n","  y_pred = (modelLSTM.predict(X_test) > 0.5).astype(\"int32\")\n","\n","  # Print confusion matrix\n","  cm = confusion_matrix(y_test, y_pred)\n","  print(cm)\n","\n","  # Visualize confusion matrix\n","  sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\")\n","  plt.title(\"Confusion Matrix\")\n","  plt.xlabel(\"Predicted Label\")\n","  plt.ylabel(\"True Label\")\n","  # plt.show()\n","  plt.savefig(f'_Top-down-Framework/Result/{timestep}frames_v{version}/confusion_matrix.png')\n","  plt.close()"]},{"cell_type":"code","source":["for timestep in [30, 35, 40]:\n","  print('timestep', timestep)\n","  for version in [1, 2, 3]:\n","    print('version', version)\n","    test(timestep, version)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SBZUZg2OsTaS","executionInfo":{"status":"ok","timestamp":1685350171178,"user_tz":-420,"elapsed":81899,"user":{"displayName":"nguyen toan","userId":"14848113097500887617"}},"outputId":"fb72bb10-86d8-43a7-a189-ba4b135cf897"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["timestep 30\n","version 1\n","150/150 [==============================] - 3s 7ms/step - loss: 0.0232 - accuracy: 0.9921 - f1_m: 0.9835\n","Test loss: 0.023241009563207626\n","Test accuracy: 0.9920568466186523\n","150/150 [==============================] - 2s 4ms/step\n","rmse_Result:  0.6082619112522553\n","150/150 [==============================] - 1s 4ms/step\n","[[3564   15]\n"," [  23 1182]]\n","version 2\n","150/150 [==============================] - 2s 6ms/step - loss: 0.0244 - accuracy: 0.9912 - f1_m: 0.9806\n","Test loss: 0.02435060404241085\n","Test accuracy: 0.9912207126617432\n","150/150 [==============================] - 2s 6ms/step\n","rmse_Result:  0.6066516688972178\n","150/150 [==============================] - 1s 6ms/step\n","[[3572    7]\n"," [  35 1170]]\n","version 3\n","150/150 [==============================] - 2s 6ms/step - loss: 0.0152 - accuracy: 0.9958 - f1_m: 0.9919\n","Test loss: 0.01515480037778616\n","Test accuracy: 0.9958193898200989\n","150/150 [==============================] - 2s 4ms/step\n","rmse_Result:  0.6086730787277363\n","150/150 [==============================] - 1s 4ms/step\n","[[3577    2]\n"," [  18 1187]]\n","timestep 35\n","version 1\n","136/136 [==============================] - 7s 6ms/step - loss: 0.0088 - accuracy: 0.9979 - f1_m: 0.9947\n","Test loss: 0.00884685106575489\n","Test accuracy: 0.9979296326637268\n","136/136 [==============================] - 2s 5ms/step\n","rmse_Result:  0.5949752692091161\n","136/136 [==============================] - 1s 4ms/step\n","[[3330    4]\n"," [   5 1008]]\n","version 2\n","136/136 [==============================] - 3s 8ms/step - loss: 0.0083 - accuracy: 0.9970 - f1_m: 0.9927\n","Test loss: 0.008253908716142178\n","Test accuracy: 0.9970094561576843\n","136/136 [==============================] - 2s 4ms/step\n","rmse_Result:  0.5954348416252119\n","136/136 [==============================] - 1s 4ms/step\n","[[3329    5]\n"," [   8 1005]]\n","version 3\n","136/136 [==============================] - 2s 6ms/step - loss: 0.0210 - accuracy: 0.9942 - f1_m: 0.9863\n","Test loss: 0.02097744680941105\n","Test accuracy: 0.9942489266395569\n","136/136 [==============================] - 2s 5ms/step\n","rmse_Result:  0.5926410684863598\n","136/136 [==============================] - 1s 4ms/step\n","[[3334    0]\n"," [  25  988]]\n","timestep 40\n","version 1\n","124/124 [==============================] - 2s 6ms/step - loss: 0.0088 - accuracy: 0.9982 - f1_m: 0.9862\n","Test loss: 0.008765453472733498\n","Test accuracy: 0.9982219934463501\n","124/124 [==============================] - 2s 5ms/step\n","rmse_Result:  0.5800919936562136\n","124/124 [==============================] - 1s 5ms/step\n","[[3088    1]\n"," [   6  842]]\n","version 2\n","124/124 [==============================] - 2s 6ms/step - loss: 0.0103 - accuracy: 0.9959 - f1_m: 0.9823\n","Test loss: 0.010317305102944374\n","Test accuracy: 0.9959359765052795\n","124/124 [==============================] - 2s 6ms/step\n","rmse_Result:  0.5786828084127432\n","124/124 [==============================] - 1s 6ms/step\n","[[3087    2]\n"," [  14  834]]\n","version 3\n","124/124 [==============================] - 2s 6ms/step - loss: 0.0135 - accuracy: 0.9944 - f1_m: 0.9771\n","Test loss: 0.013513976708054543\n","Test accuracy: 0.9944120049476624\n","124/124 [==============================] - 2s 5ms/step\n","rmse_Result:  0.5798537743654675\n","124/124 [==============================] - 1s 5ms/step\n","[[3072   17]\n"," [   5  843]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"7sKKwXFI67uA"},"source":["# **Train model SVM**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KDPi1ZNXYxNS"},"outputs":[],"source":["import numpy as np\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, confusion_matrix\n","import joblib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pv38WKVor4iM"},"outputs":[],"source":["timestep = 20\n","param_grid = {'C': [1], 'kernel': ['linear', 'rbf']}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cQdZuxoCP84a"},"outputs":[],"source":["with open(f'/content/drive/MyDrive/PBL5/_Top-down-Framework/features/features_{timestep}frames.npy', \"rb\") as f:\n","    X = np.load(f)\n","    f.close()\n","with open(f'/content/drive/MyDrive/PBL5/_Top-down-Framework/features/labels_{timestep}frames.npy', \"rb\") as f:\n","      y = np.load(f)\n","      f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l3haLOwiYwEU"},"outputs":[],"source":["X = X.reshape([len(X), 5 * timestep])\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0, shuffle=True)"]},{"cell_type":"code","source":["svclassifier = SVC()\n","grid_search = GridSearchCV(svclassifier, param_grid, cv=5)\n","grid_search.fit(X_train, y_train)"],"metadata":{"id":"R5onCZZDS0Ni","colab":{"base_uri":"https://localhost:8080/","height":117},"executionInfo":{"status":"ok","timestamp":1684589590781,"user_tz":-420,"elapsed":181009,"user":{"displayName":"Phan Tien Dat","userId":"12135962770115252033"}},"outputId":"7abb317e-86fc-4e95-c2e9-c8d2b2dc85dd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=5, estimator=SVC(),\n","             param_grid={'C': [1], 'kernel': ['linear', 'rbf']})"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n","             param_grid={&#x27;C&#x27;: [1], &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n","             param_grid={&#x27;C&#x27;: [1], &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["y_pred = grid_search.predict(X_test)\n","\n","print('accuracy =', accuracy_score(y_test, y_pred))\n","print(classification_report(y_test, y_pred))\n","\n","# Print confusion matrix\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)\n","# print(\"Best value of C:\", grid_search.best_params_['C'])\n","\n","# Visualize confusion matrix\n","sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\")\n","plt.title(\"Confusion Matrix\")\n","plt.xlabel(\"Predicted Label\")\n","plt.ylabel(\"True Label\")\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":709},"id":"u5pOiNY5G5Oh","executionInfo":{"status":"ok","timestamp":1684233031359,"user_tz":-420,"elapsed":2694,"user":{"displayName":"Phan Tien Dat","userId":"12135962770115252033"}},"outputId":"552014f3-b1bf-4c9b-b416-db4fd42d5ac7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy = 0.9515316827528326\n","              precision    recall  f1-score   support\n","\n","           0       0.95      0.99      0.97      3768\n","           1       0.97      0.79      0.87       998\n","\n","    accuracy                           0.95      4766\n","   macro avg       0.96      0.89      0.92      4766\n","weighted avg       0.95      0.95      0.95      4766\n","\n","[[3744   24]\n"," [ 207  791]]\n","Best value of C: 10\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["best_C = grid_search.best_params_['C']\n","svclassifier_best = SVC(kernel='linear', C=best_C)\n","svclassifier_best.fit(X_train, y_train)\n","\n","# Save the trained model\n","joblib.dump(svclassifier_best, f'/content/drive/MyDrive/PBL5/_Top-down-Framework/SVMmodels/svm_trained{timestep}_C{best_C}.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FZZJBjbXHlOQ","executionInfo":{"status":"ok","timestamp":1684233450494,"user_tz":-420,"elapsed":231831,"user":{"displayName":"Phan Tien Dat","userId":"12135962770115252033"}},"outputId":"35eb9645-2cfb-4441-98f1-9bf43d4e7371"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/PBL5/_Top-down-Framework/SVMmodels/svm_trained20_C10.pkl']"]},"metadata":{},"execution_count":19}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}